{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM4ZOa1zFTos5gYW7ObAEOe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yexf308/AppliedStatistics/blob/main/12_Feature_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLCrdSxN9D-1"
      },
      "outputs": [],
      "source": [
        "%pylab inline "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\def\\m#1{\\mathbf{#1}}$\n",
        "$\\def\\mm#1{\\boldsymbol{#1}}$\n",
        "$\\def\\mb#1{\\mathbb{#1}}$\n",
        "$\\def\\c#1{\\mathcal{#1}}$\n",
        "$\\def\\mr#1{\\mathrm{#1}}$\n",
        "$\\newenvironment{rmat}{\\left[\\begin{array}{rrrrrrrrrrrrr}}{\\end{array}\\right]}$\n",
        "$\\newcommand\\brm{\\begin{rmat}}$\n",
        "$\\newcommand\\erm{\\end{rmat}}$\n",
        "$\\newenvironment{cmat}{\\left[\\begin{array}{ccccccccc}}{\\end{array}\\right]}$\n",
        "$\\newcommand\\bcm{\\begin{cmat}}$\n",
        "$\\newcommand\\ecm{\\end{cmat}}$\n"
      ],
      "metadata": {
        "id": "5fQ-EJqU9j6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction\n",
        "Machine Learning = Data + **Feature** + Model\n",
        "\n",
        "Data comes in all forms:\n",
        "\n",
        "- Real,continuous\tfeatures: $\\m{x}\\in \\mb{R}^d$.  \n",
        "\n",
        "- Categorical\tdata: $\\m{x} = [\\text{Red, 12203, Finished basement}].$\n",
        "\n",
        "- Structured\tdata: Tree-style data.\n",
        "\n",
        "- Text data.\n",
        "\n",
        "- Image data.\n",
        "\n",
        "- Audio data. \n",
        "\n",
        "- Time-series\tdata. \n",
        "\n",
        "\n",
        "What shall we do if we have the missing data entry?"
      ],
      "metadata": {
        "id": "5e1XuiSa9rPd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Real vectors\n",
        "\n",
        "**Q1:**\n",
        "If many features are\tuninformative, \n",
        "\n",
        "- Feature selection (LASSO). \n",
        "- Dimensional Reduction, like auto-encoder. \n",
        "- Transform the features. \n",
        "- Collect new data.\n",
        "\n",
        "\n",
        "**Q2**:\n",
        "If many features are\tincomparable, \n",
        "\n",
        "- Standardization\n",
        "- Normalization \n",
        "\n",
        "**Q3:**\n",
        "If \tmany\tfeatures\tare\tsuperfluous\tor\tcorrelated\twith\teach\tother. \n",
        "- Use PCA to de-correlation. \n",
        "\n",
        "\n",
        "Common pre-processing\tpipeline:\t\t\n",
        "1. Standardize\tdata\t(de-mean,\tdivide\tby\tstandard\tdeviation)\t\n",
        "2. Project\tdown\tto\tlower\tdimensional\trepresentation\tusing\tPCA\t\n",
        "3. Apply\texact\ttransformation\tto\tTraining\tand\tTesting.\t\n",
        "\n",
        "\n",
        "\n",
        "### 2. Categorical data\n",
        "Many\tmachine\tlearning\talgorithms\t(e.g.,\tlinear\tpredictors)\trequire\treal valued-vectors\n",
        "to\tmake\tpredictions.\tAnd\twe\twant\tthose\treal-valued\tnumbers\tto\tbe\tcorrelated with the label.\n",
        "\n",
        "- One-hot\tencoding:\tAssign\tcanonical\tvector\tto\teach\tcategorical\tvariable. For example, $\\text{color}\\in \\{\\text{red, yellow, blue}\\}$. \n",
        "\n",
        "- zip code: 12203. The dimension is too large, we can group them say 122xx.\n",
        "\n",
        "### 3. Structured data\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://github.com/yexf308/AppliedStatistics/blob/main/image/structured.png?raw=true\" width=\"600\" />\n",
        "\n",
        "\n",
        "### 4. Image data\n",
        "Find\ta\tfeature\tvector\tfor\tthe\timage:\t\n",
        "• Recognition\t\n",
        "• Identification\t\n",
        "• Detection\t\n",
        "• Image\tclassification\t\n",
        "\n",
        "**Computer Vision**: CNN, Resnet... I didn't cover it in this course. This itself is a separate course. \n",
        "\n",
        "\n",
        "### 5. Text data. \n",
        "Can we embed words\n",
        "into a latent space? This embedding came from\n",
        "directly querying for\n",
        "relationships. **Natural Language Processing** This again is a separate course. \n",
        "\n",
        "- **word2vec** is a popular\n",
        "unsupervised learning\n",
        "approach that just uses a text\n",
        "corpus\n",
        "\n",
        "- **Bag of Words** and tfidf. (check BBC clustering HW problem.)\n",
        "\n",
        "- **Bert**\n",
        "\n",
        "- Document Clustering Based On **Non-negative Matrix\n",
        "Factorization**. \n",
        "\n",
        "### 6. Audio data, Time-series data\n",
        "Hidden Markov Models, Recurrent Neural Network"
      ],
      "metadata": {
        "id": "1w90BSDPAOOQ"
      }
    }
  ]
}