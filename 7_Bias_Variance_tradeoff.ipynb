{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6.Bias-Variance tradeoff.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN8zKb/H+Q/Nsk0eSqqPS9y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yexf308/AppliedStatistics/blob/main/6_Bias_Variance_tradeoff.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMpJSeyrGOBq"
      },
      "outputs": [],
      "source": [
        "%pylab inline \n",
        "import pandas as pd\n",
        "from scipy import linalg\n",
        "from itertools import combinations\n",
        "import scipy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\def\\m#1{\\mathbf{#1}}$\n",
        "$\\def\\mm#1{\\boldsymbol{#1}}$\n",
        "$\\def\\mb#1{\\mathbb{#1}}$\n",
        "$\\def\\c#1{\\mathcal{#1}}$\n",
        "$\\def\\mr#1{\\mathrm{#1}}$\n",
        "$\\newenvironment{rmat}{\\left[\\begin{array}{rrrrrrrrrrrrr}}{\\end{array}\\right]}$\n",
        "$\\newcommand\\brm{\\begin{rmat}}$\n",
        "$\\newcommand\\erm{\\end{rmat}}$\n",
        "$\\newenvironment{cmat}{\\left[\\begin{array}{ccccccccc}}{\\end{array}\\right]}$\n",
        "$\\newcommand\\bcm{\\begin{cmat}}$\n",
        "$\\newcommand\\ecm{\\end{cmat}}$\n"
      ],
      "metadata": {
        "id": "WJIty7uGKJA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bias-Variance Tradeoff\n",
        "To fully understand cross-validation, we need to take back to think about the parameter $\\mm\\theta$. \n",
        "\n",
        "### Background\n",
        "Let $\\hat{\\mm \\theta}$ is the estimator and $\\hat{\\mm \\theta}(\\c{D})$ is the estimand on the dataset $\\c{D}$. \n",
        "\n",
        "**Assumption**: Dataset $\\c{D}$ is random variable drown from some true but unknown distribution, $p^*$, this induces a distribution with the parameter over the estimand, $p(\\hat{\\mm \\theta}(\\c{D}))$, which is the sampling distribution. \n",
        "\n",
        "### Bias of an estimator\n",
        "The bias of an estimator/model is \n",
        "\\begin{align}\n",
        "\\text{bias}(\\hat{\\mm\\theta}) = \\mb{E}[\\hat{\\mm\\theta}(\\c{D})] - \\mm\\theta^*\n",
        "\\end{align}\n",
        "where $\\mm\\theta^*$ is the true parameter value, and the expectation is wrt \"natureâ€™s distribution\" $p(\\c{D}|\\mm\\theta^*)$. If\n",
        "the bias is zero, the estimator is called **unbiased**. \n",
        "\n",
        "- the MLE for a Gaussian mean is\n",
        "unbiased: \n",
        "\\begin{align}\n",
        "\\text{bias}(\\hat \\mu) = \\mb{E}[\\hat\\mu]-\\mu = \\mb{E}\\left[\\frac{1}{N}\\sum_{i=1}^N x^{(i)}\\right] - \\mu = \\frac{N\\mu}{N} - \\mu =0\n",
        "\\end{align}\n",
        "\n",
        "- the MLE for a Gaussian variance, $\\hat\\sigma^2 = \\frac{1}{N}\\sum_{i=1}^N (x^{(i)}-\\bar x)^2$ is not unbiased estimator of $\\sigma^2$, $\\mb{E}[\\hat\\sigma^2]=\\frac{N-1}{N}\\sigma^2$. \n",
        "\\begin{align}\n",
        "\\text{bias}(\\hat \\sigma^2) = \\mb{E}[\\bar x]-\\sigma^2 = -\\frac{1}{N}\\sigma^2.\n",
        "\\end{align}\n",
        "The MLE estimator slightly underestimates the variance. \n",
        "\n",
        "### Variance of an estimator\n",
        "It is not enough to sure the estimator is unbiased. For example, we can use the first data point in the sample as my estimator, which is also unbiased for the mean, but will be far away from $\\mm\\theta^*$ in general. \n",
        "\n",
        "Define the variance of an estimator: \n",
        "\\begin{align}\n",
        "\\mb{V}[\\hat{\\mm\\theta}] = \\mb{E}[\\hat{\\mm\\theta}^2]-\\left(\\mb{E}[\\hat{\\mm\\theta}]\\right)^2\n",
        "\\end{align}\n",
        "where the expectation is taken wrt to $p(\\c{D}|\\mm\\theta^*)$. \n",
        "\n",
        "- the MLE for a Gaussian mean\n",
        "\\begin{align}\n",
        "\\mb{V}[\\hat\\mu] = \\mb{V}\\left[\\frac{1}{N}\\sum_{i=1}^N x^{(i)}\\right] = \\frac{1}{N^2}  \\sum_{i=1}^N \\mb{V}\\left[  x^{(i)}\\right]=\\frac{\\sigma^2}{N}\n",
        "\\end{align}\n",
        "\n",
        "- the MLE for a Gaussian variance,\n",
        "\\begin{align}\n",
        "\\mb{V}[\\hat \\sigma^2] =\\frac{2(N-1)}{N^2}\\sigma^4\n",
        "\\end{align}\n",
        "why?\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HjhepfncKV_m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Statistical Learning \n",
        "Assume \n",
        "\\begin{align}\n",
        "y=f(\\m{x})+\\epsilon\n",
        "\\end{align}\n",
        "$f$ is the fixed unknown function and $\\epsilon$ is a random error term and is independent of $\\m{x}$ and has mean zero. $\\hat f(\\m{x};\\c{D})$ is our estimate for $f$ with the training dataset $\\c{D}$ and we have the prediction $\\hat y = \\hat f(\\m{x}; \\c{D})$.\n",
        "\n",
        "Fit our methods on training dataset $\\{\\m{x}^{(i)}, y^{(i)}\\}_{i=1}^N$ and compute predicted value $\\hat f(\\m{x}^{(i)})$. If these predicted values are approximately equal to $y^{(i)}$, then RSS/MSE/NLL will be small. But we are not interested in whether $\\hat f(\\m{x}^{(i)}) \\approx y^{(i)}$. Instead we want to know whether $\\hat f(\\m{x}; \\c{D})$ is equal to $y$, where $\\{\\m{x}, y\\}$ is previously unseen test observation not used to train the model. \n",
        "\n",
        "**Goal**: to choose the method gives the lowest test MSE. If we had a large number of test data, we want to **minmize the expected test MSE** at $\\m{x}$,  $\\mb{E}[(y-\\hat f(\\m{x}))^2]$. \n",
        "\n",
        "\n",
        "In estimation, \n",
        "- Training MSE, $\\frac{1}{|\\c{D}|}\\sum_{(\\m{x}^{(i)}, y^{(i)})\\in \\c{D}} \\left(y^{(i)} - \\hat f(\\m{x}^{(i)})\\right)^2$\n",
        "\n",
        "- Testing MSE, $\\frac{1}{|\\c{T}|}\\sum_{(\\m{x}^{(i)}, y^{(i)})\\in \\c{T}} \\left(y^{(i)} - \\hat f(\\m{x}^{(i)})\\right)^2$ where $\\c{T}$ is the test dataset. Note $\\c{D}\\cap \\c{T}=\\emptyset$. \n",
        "\n",
        "\n",
        "**Mathematical property:**\n",
        "- $f$ is deterministic and independent of $\\c{D}$, $\\mb{E}[f]=f$. \n",
        "\n",
        "- $\\hat f$ is a random variable since it depends on the random variable $\\c{D}$.\n",
        "\n",
        "- $\\mb{E}[\\epsilon] =0$, so $\\mb{E}[y]=\\mb{E}[f]=f$.\n",
        "\n",
        "- $\\mb{V}[\\epsilon]=\\sigma^2$, so $\\mb{V}[y]=\\mb{E}[(y-\\mb{E}[y])^2]=\\mb{E}[(y-f)^2]=\\mb{E}[\\epsilon^2]=\\mb{V}[\\epsilon]=\\sigma^2$\n",
        "\n",
        "- $\\epsilon$ and $\\hat f$ are independent, **Bias-Variance** \n",
        "\\begin{align*}\n",
        "\\mb{E}[(y-\\hat f)^2] &= \\mb{E}[(f+\\epsilon -\\hat f)^2]\\\\\n",
        "&=\\mb{E}\\left[\\left(f-\\mb{E}[\\hat f]+\\epsilon  +\\mb{E}[\\hat f] -\\hat f\\right)^2\\right] \\\\\n",
        "&= \\mb{E}\\left[\\left(f-\\mb{E}[\\hat f]\\right)^2 + \\epsilon^2 + \\left(\\mb{E}[\\hat f] -\\hat f\\right)^2 + 2\\left(f-\\mb{E}[\\hat f]\\right)\\epsilon + 2\\epsilon \\left(\\mb{E}[\\hat f] -\\hat f\\right) + 2\\left(f-\\mb{E}[\\hat f]\\right) \\left(\\mb{E}[\\hat f] -\\hat f\\right) \\right]\\\\\n",
        "&= \\left(f-\\mb{E}[\\hat f]\\right)^2 +\\mb{E}[\\epsilon^2] + \\mb{E}\\left[\\left(\\mb{E}[\\hat f] -\\hat f\\right)^2\\right] \\ \\ \\text{due to } \\mb{E}[\\epsilon]= 0, \\mb{E}\\left[\\left(\\mb{E}[\\hat f] -\\hat f\\right)\\right] = 0 \\\\\n",
        "&= \\boxed{ \\left[\\text{Bias}(\\hat f)\\right]^2 + \\mb{V}[\\hat f]+\\mb{V}[\\epsilon] }\n",
        "\\end{align*}\n",
        "All three quantities are non-negative, and the first two are reducible error and the last one is irreducible error. So the expected test MSE should never lie below $\\mb{V}[\\epsilon]$. \n",
        "\n",
        "### Apply to models \n",
        "\n",
        "- Bias of estimated function $\\hat f$: $\\quad\\text{Bias}(\\hat f)=\\mb{E}[\\hat f]-f$. \n",
        "  - An error from erroneous assumptions in the learning algorithm. \n",
        "  -  High bias can cause an algorithm to miss the relevant relations between inputs and outputs (**underfitting**).\n",
        "\n",
        "- Variance of estimated function $\\hat f$: $\\quad \\mb{V}[\\hat f] = \\mb{E}\\left[\\left(\\mb{E}[\\hat f] -\\hat f\\right)^2\\right]$.\n",
        "\n",
        "  - The amount by which $\\hat f$ would change if we\n",
        "estimated it using a different training data set.\n",
        "  - If a method has high variance\n",
        "then small changes in the training data can result in large changes in $\\hat f$. In general more flexible statistical methods have higher variance. (**overfitting**)\n",
        "\n",
        "\n",
        "We need to select a statistical learning method that simultaneously achieves\n",
        "**low variance** and **low bias**. This is very challenging. \n",
        "\n",
        "- Very low variance and high bias:  fitting a line to the data.\n",
        "\n",
        "- Very low bias and high variance: drawing a curve that passes through every single training observation. \n",
        "\n",
        "We use more flexible methods, the variance will\n",
        "increase and the bias will decrease. \n",
        "We might be wise to use a biased estimator, so long as it reduces our variance by more than the square of the bias.  \n",
        "\n"
      ],
      "metadata": {
        "id": "R8GeJizrgD5A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/yexf308/AppliedStatistics/blob/main/image/BV1.png?raw=true\" width=\"400\" />\n",
        "<img src=\"https://github.com/yexf308/AppliedStatistics/blob/main/image/BV2.png?raw=true\" width=\"500\" />\n",
        "\n",
        "<img src=\"https://github.com/yexf308/AppliedStatistics/blob/main/image/BV3.png?raw=true\" width=\"500\" />\n",
        "\n",
        "\n",
        "It matches with  philosophical idea, **Occamâ€™s razor**, aka, Law of Economy, or Law of Parsimony. The main idea is **The simplest consistent explanation is the best**. "
      ],
      "metadata": {
        "id": "G-JlbUy0FLqa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 1: MAP estimator for a Gaussian mean\n",
        "Suppose we want to estimate the mean of a Gaussian from dataset $\\{x^{(i)}\\}_{i=1}^N$. We assume the data is sampled from $x^{(i)}\\sim \\c{N}(\\mu^*=1, \\sigma^2)$. \n",
        "\n",
        " - use MLE $\\hat \\mu = \\frac{1}{N}\\sum_{i=1}^N x^{(i)}$. The bias is 0 and the variance $\\mb{V}[\\hat\\mu] = \\frac{\\sigma^2}{N}$. The reducible error in total is $\\frac{\\sigma^2}{N}$. \n",
        "\n",
        " - use MAP estimate. Under the Gaussian prior of the form $\\c{N}(\\mu_0, \\frac{\\sigma^2}{\\kappa_0})$\n",
        "\\begin{align}\n",
        "\\tilde{\\mu}=\\frac{N}{N+\\kappa_0}\\hat\\mu +\\frac{\\kappa_0}{N+\\kappa_0}\\mu_0=(1-\\lambda)\\hat\\mu+\\lambda\\mu_0\n",
        "\\end{align}\n",
        "where $0< \\lambda< 1$  controls how much we trust the MLE compared to our prior. The bias and variance are given by\n",
        "\\begin{align}\n",
        "&\\mb{E}[\\tilde\\mu]-\\mu^*= \\lambda(\\mu_0-\\mu^*)\\\\\n",
        "&\\mb{V}[\\tilde\\mu] = (1-\\lambda)^2\\frac{\\sigma^2}{N}\n",
        "\\end{align}\n",
        "So although the MAP estimate is biased (assuming $\\lambda >0$), it has lower variance. The reducible error in total is $\\lambda^2(\\mu_0-\\mu^*)^2+(1-\\lambda)^2\\frac{\\sigma^2}{N}$. \n",
        "\n",
        "It is possible that $\\lambda^2(\\mu_0-\\mu^*)^2+(1-\\lambda)^2\\frac{\\sigma^2}{N} < \\frac{\\sigma^2}{N}$. In general, for this type shrinkage estimate, \n",
        "Then $0<\\lambda<\\frac{2\\sigma^2}{N(\\mu_0-\\mu^*)^2+\\sigma^2}$. More importantly, if $\\lambda^* = \\frac{\\sigma^2}{N(\\mu_0-\\mu^*)^2+\\sigma^2}$, then expected test MSE reaches the minimum,  so we have improved our\n",
        "estimator!\n",
        "\n",
        "\n",
        "What fundamentally happens in this example is that because weâ€™re\n",
        "using squared error, if we can shrink the error of the worst estimate (even if we correspondingly increase\n",
        "the error of the other estimates) weâ€™ll shrink the overall error, because squared error very heavily **punishes\n",
        "large errors**, but only moderately punishes moderate errors. One way of interpreting this paradox is that\n",
        "the squared error isnâ€™t the only error you might care about. You might really care about the sum of the\n",
        "absolute errors (instead of their squares) in which case, you wouldnâ€™t see a similar effect.\n",
        "\n",
        "Regardless of the interpretation, this result is **counter-intuitive**. We just decided to guess smaller values\n",
        "than our samples gave us. On its face the idea is crazy â€“ we only would have come up with such an idea\n",
        "if we had broken down our error into bias and variance and could see where the error was coming from.\n",
        "This is the real takeaway of this calculation â€“ if you can understand where your error is coming from, you\n",
        "might be able to generate new ideas for what to do about it.\n",
        "\n"
      ],
      "metadata": {
        "id": "Qrh5gCoQJNAj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 2: Ridge regression\n",
        "In Ridge regression, we use MAP estimation, \n",
        "\\begin{align}\n",
        "\\hat{\\m w}_{\\text{ridge}} &= \\arg\\min_{\\m{w}} \\left(\\|\\mathbf{X}\\mathbf{w}-\\mathbf{y}\\|_2^2+\\lambda\\|\\m{w}\\|_2^2\\right) \\\\\n",
        "&=(\\m{X}^\\top\\m{X}+\\lambda \\m{I}_D)^{-1}\\m{X}^\\top \\m{y}\n",
        "\\end{align}\n",
        "\n",
        "The model is $\\m{y} = \\m{xw}+\\mm{\\epsilon}$. Assume $\\m{X}^\\top\\m{X}=N\\m{I}_D$. ($\\m{X}_{ij}\\sim \\c{N}(0,1)$ ). Then\n",
        "\\begin{align}\n",
        "\\hat{\\m w}_{\\text{ridge}}  &= (\\m{X}^\\top\\m{X}+\\lambda \\m{I}_D)^{-1}\\m{X}^\\top (\\m{Xw}+\\mm{\\epsilon}) \\\\\n",
        " &= \\frac{N}{N+\\lambda} \\m{w} + \\frac{1}{N+\\lambda} \\m{X}^\\top \\mm{\\epsilon} \n",
        "\\end{align}\n",
        "\n",
        "- Bias: \n",
        "\\begin{align}\n",
        "\\mb{E}[\\hat f]-f=\\mb{E}[\\m{x}\\hat{\\m w}_{\\text{ridge}} ] - \\m{xw} = \\frac{\\lambda}{N+\\lambda} \\m{xw} \n",
        "\\end{align}\n",
        "\n",
        "- Variance: \n",
        "\\begin{align}\n",
        "\\mb{V}[\\hat f] &= \\mb{V}[\\m{x}\\hat{\\m w}_{\\text{ridge}}] =  \\m{x}\\mb{V}[\\hat{\\m w}_{\\text{ridge}}] \\m{x}^\\top\\\\\n",
        "&= \\m{x} \\left[\\frac{1}{N+\\lambda} \\m{X}^\\top \\sigma^2 \\m{I}_N \\frac{1}{N+\\lambda}\\m{X}  \\right]\\m{x}^\\top \\\\\n",
        "&=\\frac{N\\sigma^2}{(N+\\lambda)^2}\\|\\m{x}\\|_2^2\n",
        "\\end{align}\n",
        "\n",
        "- Bias-Variance \n",
        "\\begin{align}\n",
        "\\mb{E}[(y-\\hat f)^2]  = \\sigma^2  + \\frac{\\lambda^2}{(N+\\lambda)^2} (\\m{x}\\m{w})^2 + \\frac{N\\sigma^2}{(N+\\lambda)^2}\\|\\m{x}\\|_2^2\n",
        "\\end{align}\n"
      ],
      "metadata": {
        "id": "BhM11WwVoBJc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bayesian hypothesis testing (optional)\n",
        "Consider we have several candidate (parametric) models (e.g., polynomial regression with different orders, or neural networks with different number of layers), and we want to choose the 'right' one. \n",
        "\n",
        "### Two models\n",
        "If we have two hypotheses models $M_0$ and $M_1$, the optimal decision is to pick $M_1$ iff $p(M_1 |\\c{D})>p(M_0 |\\c{D}) $. We can define the **Bayes factor** $BF(1,0) = \\frac{p(M_1 |\\c{D})}{p(M_0 |\\c{D})}$. If $BF>10$, it shows stronge evidence to choose $M_1$. \n",
        "\n",
        "### Mutiple models\n",
        "Suppose we have a set $\\c{M}$ of more than 2 models, and we want to pick the most likely. \n",
        "\n",
        "- If we have a 0-1 loss, the optimal action is to pick the most probable model: $\\hat{M} = \\arg\\max_{M\\in \\c{M}} p(M|\\c{D})$, where the posterior probability over models are \n",
        "\\begin{align}\n",
        "p(M|\\c{D}) = \\frac{p(\\c{D}|M) p(M)}{\\sum_{M\\in\\c{M}}p(\\c{D}|M) p(M)}\n",
        "\\end{align}\n",
        "\n",
        "- If we choose uniform prior, i.e., $p(M)=1/|\\c{M}|$, then $\\hat{M} = \\arg\\max_{M\\in \\c{M}} p(\\c{D}|M)$. \n",
        "And the quantity $p(\\c{D}|M)=\\int p(\\c{D}|\\mm{\\theta}, M)p(\\mm{\\theta}|M)d\\mm{\\theta}$\n",
        "This is known as the **marginal likelihood**, or the **evidence** for model $m$. Intuitively, it is the\n",
        "likelihood of the data averaged over all possible parameter values, weighted by the prior $p(\\mm\\theta|M)$. \n",
        "\n",
        "### Bayesian Occamâ€™s razor\n",
        "\n",
        "- If we have two models $M_1$ and $M_2$, and $M_2$ is more complex. Suppose both models can explain the data by optimizing their parameters, i.e., for which both likelihood $p(\\c{D}|\\hat{\\mm{\\theta}}_1, M_1)$ and  $p(\\c{D}|\\hat{\\mm{\\theta}}_2, M_2)$ are both large. Intuitively we should **prefer $M_1$**. This is **Occam's razor.**\n",
        "\n",
        "- If we use the marginal likelihood to rank models, we can compare relative predictive ability of simple and complex models. Note $\\sum_{\\c{D}'}p(\\c{D}'|M)=1$, where the sum is over all possible datasets. \n",
        "\n",
        "  - Complex model $M_3$ must spread the predicted probability mass thinly. The assigned probability to $\\c{D}_0$ is also low.  \n",
        "\n",
        "  - Simple model $M_1$ is too simple and assigns low probability to $c{D}_0$\n",
        "\n",
        "  - $M_2$ predicts the observed data with a reasonable degree of confidence, but does not predict too many other things. \n",
        "\n",
        "\n",
        "<img src=\"https://github.com/yexf308/AppliedStatistics/blob/main/image/occam.png?raw=true\" width=\"500\" />\n",
        "\n",
        "## Bayesian information criterion (BIC)\n",
        "Usually the marginal probability $p(\\c{D}|M)$ is very hard to compute, since it requires marginalize over the parameter space. We need some approximation here. \n",
        "\n",
        "**Assume the posteror function $p(\\mm{\\theta}|\\c{D})$ is Gaussian**, $p(\\mm\\theta| \\c{D})=\\frac{p(\\mm\\theta, \\c{D})}{p(\\c{D})}\\triangleq \\frac{1}{Z}\\exp(-\\c{E}(\\mm\\theta))$, where energy function $\\c{E}(\\mm\\theta)=-\\log p(\\mm\\theta, \\c{D})$ and $Z=p(\\c{D})$ is the normalization constant. If we perform taylor expansion of $\\c{E}(\\mm\\theta)$ about the MLE $\\hat{\\mm{\\theta}}$, \n",
        "\\begin{align}\n",
        "\\c{E}(\\mm\\theta)\\approx \\c{E}(\\hat{\\mm\\theta}) +\\frac{1}{2}(\\mm\\theta -\\hat{\\mm\\theta})^\\top \\m{H}(\\mm\\theta -\\hat{\\mm\\theta})\n",
        "\\end{align}\n",
        "The first order is gone due to MLE is the local stationary point and $\\m{H}$ is the Hessian. \n",
        "Then \n",
        "\\begin{align}\n",
        "&p(\\mm\\theta, \\c{D}) \\approx \\exp(-\\c{E}(\\hat{\\mm\\theta})) \\exp\\left[-\\frac{1}{2}(\\mm\\theta -\\hat{\\mm\\theta})^\\top \\m{H}(\\mm\\theta -\\hat{\\mm\\theta})\\right] \\\\\n",
        "& p(\\mm\\theta|\\c{D}) \\approx \\c{N}(\\mm\\theta|\\hat{\\mm{\\theta}}, \\m{H}^{-1}) \n",
        "\\end{align}\n",
        "\n",
        "\n",
        "Then the marginal probability \n",
        "\\begin{align}\n",
        "p(\\mm{\\theta}|\\c{D}) &\\approx \\int p(\\c{D}|\\mm{\\theta})\\c{N}(\\mm\\theta|\\hat{\\mm{\\theta}}, \\m{H}^{-1})  d\\mm{\\theta} \\\\\n",
        "&=\\int \\exp\\left(-N \\left(-\\frac{1}{N}\\log p(\\c{D}|\\mm{\\theta})-\\frac{1}{N}\\log \\c{N}(\\mm\\theta|\\hat{\\mm{\\theta}}, \\m{H}^{-1}) \\right)\\right) d\\mm\\theta \\\\\n",
        "&\\approx p(\\c{D}|\\hat{\\mm\\theta})\\c{N}(\\hat{\\mm\\theta}|\\hat{\\mm{\\theta}}, \\m{H}^{-1})(2\\pi)^{d/2}|\\m{H}|^{-1/2}N^{-d/2}\n",
        "\\end{align}\n",
        "The log of the marginal probability is \n",
        "\\begin{align}\n",
        "\\log p(\\mm{\\theta}|\\c{D})  \\approx \\log p(\\c{D}|\\hat{\\mm\\theta}) + \\log\\c{N}(\\hat{\\mm\\theta}|\\hat{\\mm{\\theta}}, \\m{H}^{-1}) +\\frac{d}{2} \\log(2\\pi)-\\frac{1}{2}\\log|\\m{H}|-\\frac{d}{2}\\log N\n",
        "\\end{align}\n",
        "We can treat this as log-likelihood + some penalty terms. The BIC score only retains the terms that vary in $N$, since asymptotically the terms that are constant in $N$\n",
        "do not matter. So we get BIC score, \n",
        "\\begin{align}\n",
        "\\log p(\\mm{\\theta}|\\c{D})  \\approx \\log p(\\c{D}|\\hat{\\mm\\theta})-\\frac{d}{2}\\log N\n",
        "\\end{align}"
      ],
      "metadata": {
        "id": "bXHzEH_M_AR0"
      }
    }
  ]
}