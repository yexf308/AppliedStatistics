{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yexf308/AppliedStatistics/blob/main/12_Feature_extraction_and_ML_in_Practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLCrdSxN9D-1"
      },
      "outputs": [],
      "source": [
        "%pylab inline "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fQ-EJqU9j6M"
      },
      "source": [
        "$\\def\\m#1{\\mathbf{#1}}$\n",
        "$\\def\\mm#1{\\boldsymbol{#1}}$\n",
        "$\\def\\mb#1{\\mathbb{#1}}$\n",
        "$\\def\\c#1{\\mathcal{#1}}$\n",
        "$\\def\\mr#1{\\mathrm{#1}}$\n",
        "$\\newenvironment{rmat}{\\left[\\begin{array}{rrrrrrrrrrrrr}}{\\end{array}\\right]}$\n",
        "$\\newcommand\\brm{\\begin{rmat}}$\n",
        "$\\newcommand\\erm{\\end{rmat}}$\n",
        "$\\newenvironment{cmat}{\\left[\\begin{array}{ccccccccc}}{\\end{array}\\right]}$\n",
        "$\\newcommand\\bcm{\\begin{cmat}}$\n",
        "$\\newcommand\\ecm{\\end{cmat}}$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e1XuiSa9rPd"
      },
      "source": [
        "# Feature Extraction\n",
        "Machine Learning = Data + **Feature** + Model\n",
        "\n",
        "Data comes in all forms:\n",
        "\n",
        "- Real,continuous\tfeatures: $\\m{x}\\in \\mb{R}^d$.  \n",
        "\n",
        "- Categorical\tdata: $\\m{x} = [\\text{Red, 12203, Finished basement}].$\n",
        "\n",
        "- Structured\tdata: Tree-style data.\n",
        "\n",
        "- Text data.\n",
        "\n",
        "- Image data.\n",
        "\n",
        "- Audio data. \n",
        "\n",
        "- Time-series\tdata. \n",
        "\n",
        "\n",
        "What shall we do if we have the missing data entry?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1w90BSDPAOOQ"
      },
      "source": [
        "### 1. Real vectors\n",
        "\n",
        "**Q1:**\n",
        "If many features are\tuninformative, \n",
        "\n",
        "- Feature selection (LASSO). \n",
        "- Dimensional Reduction, like auto-encoder. \n",
        "- Transform the features. \n",
        "- Collect new data.\n",
        "\n",
        "\n",
        "**Q2**:\n",
        "If many features are\tincomparable, \n",
        "\n",
        "- Standardization\n",
        "- Normalization \n",
        "\n",
        "**Q3:**\n",
        "If \tmany\tfeatures\tare\tsuperfluous\tor\tcorrelated\twith\teach\tother. \n",
        "- Use PCA to de-correlation. \n",
        "\n",
        "\n",
        "Common pre-processing\tpipeline:\t\t\n",
        "1. Standardize\tdata\t(de-mean,\tdivide\tby\tstandard\tdeviation)\t\n",
        "2. Project\tdown\tto\tlower\tdimensional\trepresentation\tusing\tPCA\t\n",
        "3. Apply\texact\ttransformation\tto\tTraining\tand\tTesting.\t\n",
        "\n",
        "\n",
        "\n",
        "### 2. Categorical data\n",
        "Many\tmachine\tlearning\talgorithms\t(e.g.,\tlinear\tpredictors)\trequire\treal valued-vectors\n",
        "to\tmake\tpredictions.\tAnd\twe\twant\tthose\treal-valued\tnumbers\tto\tbe\tcorrelated with the label.\n",
        "\n",
        "- One-hot\tencoding:\tAssign\tcanonical\tvector\tto\teach\tcategorical\tvariable. For example, $\\text{color}\\in \\{\\text{red, yellow, blue}\\}$. \n",
        "\n",
        "- zip code: 12203. The dimension is too large, we can group them say 122xx.\n",
        "\n",
        "### 3. Structured data\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://github.com/yexf308/AppliedStatistics/blob/main/image/structured.png?raw=true\" width=\"600\" />\n",
        "\n",
        "\n",
        "### 4. Image data\n",
        "Find\ta\tfeature\tvector\tfor\tthe\timage:\t\n",
        "• Recognition\t\n",
        "• Identification\t\n",
        "• Detection\t\n",
        "• Image\tclassification\t\n",
        "\n",
        "**Computer Vision**: CNN, Resnet... I didn't cover it in this course. This itself is a separate course. \n",
        "\n",
        "\n",
        "### 5. Text data. \n",
        "Can we embed words\n",
        "into a latent space? This embedding came from\n",
        "directly querying for\n",
        "relationships. **Natural Language Processing** This again is a separate course. \n",
        "\n",
        "- **word2vec** is a popular\n",
        "unsupervised learning\n",
        "approach that just uses a text\n",
        "corpus\n",
        "\n",
        "- **Bag of Words** and tfidf. (check BBC clustering HW problem.)\n",
        "\n",
        "- **Bert**\n",
        "\n",
        "- Document Clustering Based On **Non-negative Matrix\n",
        "Factorization**. \n",
        "\n",
        "### 6. Audio data, Time-series data\n",
        "Hidden Markov Models, Recurrent Neural Network in my Applied Stochastic Processes course"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZ3hbwEu483G"
      },
      "source": [
        "# Machine Learning in Practice\n",
        "\n",
        "### What is Machine Learning\n",
        "- “Learning is any process by which a system improves performance from\n",
        "experience.” - Herbert Simon\n",
        "\n",
        "- A popular defintion of **machine learning**, due to Tom Mitchell:\n",
        "\"A computer program is said to learn from experience $E$ with respect to some class of tasks $T$, and performance measure $P$, if its performance at tasks in $T$, as measured by $P$, improves with experience $E$.\"\n",
        "\n",
        "- \"Machine learning is driving by looking at the rearview mirror.\" by one of my friends.\n",
        "\n",
        "### Your Test Data is Sacred!\n",
        "- Spit data into: Training set(80%), Validation set(10%) and Testing set(10%). \n",
        "- You may or may not perform the $k$-fold cross-validation, depends on the size of the data. \n",
        "- You should be causion on trajectory (sequential) data and groupable data (partial exchangeability).\n",
        "\n",
        "### Understand Your Data\n",
        "- Typical Problems: All features are zero/constant. Some features have large value (due to noise, etc.)\n",
        "- Visualize the data:\n",
        "  - Histogram each feature\n",
        "  - Scatter plot (pairs/triplets) of features\n",
        "  - Perform PCA first and then scatter plot the projected\n",
        "data.\n",
        "\n",
        "- Don’t Use Labels as Features! Use one-hot encodings! \n",
        "\n",
        "### Normalize and Standarize Data\n",
        "- Mean center, scale variance of each feature.\n",
        "- Min-Max scaling to $[-1,1]$.\n",
        "- Whiten the Data (center the mean, identity covariance).\n",
        "\n",
        "### More Data and More Features\n",
        "- More data is better!\n",
        "- More feature may not, you need to understand what features matters \n",
        "  - Naively: Use all features. (adding features should never hurt), except there are computational/overfitting/Memory problem. \n",
        "\n",
        "- Select Features: \n",
        "   - LASSO\n",
        "   - Sequential Backward Selection: Measure performance of all combinations of all but one\n",
        "feature on development set, Remove least important one, Iterate.\n",
        "   - Measure performance of all features individually, Include the most important one. Iterate. \n",
        "\n",
        "### Never Underestimate the Power of a Linear Predictor\n",
        "Linear Regression, Logistic Regression, Linear SVMs, and etc. \n",
        "\n",
        "### Unbalanced class\n",
        "<img src=\"https://github.com/yexf308/AppliedStatistics/blob/main/image/unbalanced.png?raw=true\" width=\"500\" />\n",
        "\n",
        "\n",
        "- Downsample the overrepresented classes, but doesn’t use all the data.\n",
        "- Upsample (duplicate data), but may cause overfitting and computational overhead.\n",
        "- Weight the samples (scale loss), but might not help if using stochastic\n",
        "gradient descent. \n",
        "\n",
        "### Overfitting vs Underfitting\n",
        "**Overfitting**: You do great on training data, but relatively poorly on test data\n",
        "\n",
        "- Test on validation set\n",
        "- Regularize more\n",
        "- Feature selection (fewer features). \n",
        "- Dimensional reduction\n",
        "- Get more data\n",
        "- Use simpler classifier\n",
        "\n",
        "**Underfitting:** You perform poorly on both training and test data\n",
        "- Use more features.\n",
        "- More sophisticated classifier.\n",
        "- Kernelize (infinite features!!)\n",
        "- Regularize less\n",
        "- Optimize better\n",
        "\n",
        "The rule of thumb: “Always start by overfitting” - Cris Dima \n",
        "\n",
        "### Building Large Learning Systems\n",
        "- Avoid premature statistical optimization:\n",
        "  - Spend time on the parts that matter\n",
        "  - Think a lot about features and data\n",
        "  - Start with part of the data\n",
        "\n",
        "- Don’t buy the Hype!\n",
        "  - Always start with simple models\n",
        "  - Combinations of simple models (Ensemble Methods). \n",
        "\n",
        "\n",
        "### Data Science is NOT Easy! \n",
        "- Be prepared.\n",
        "- Ready to learn everyday. Always open-minded. \n",
        "- Able to test new stuffs and implement new algorithms. \n",
        "- Mathematics + Statistics + Computer Science \n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.8 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}