{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM0CYfnqmlTTQ039ukw0LYs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yexf308/AppliedStatistics/blob/main/Homework/HW3/565Fa22HW3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lRxrr9CMy-N",
        "outputId": "da4fb1fc-d159-4d68-adc7-1bffe8be5236"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        }
      ],
      "source": [
        "%pylab inline \n",
        "import pandas as pd\n",
        "from scipy import linalg\n",
        "from itertools import combinations\n",
        "import scipy\n",
        "import scipy.io as io\n",
        "import scipy.sparse as sparse"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\def\\m#1{\\mathbf{#1}}$\n",
        "$\\def\\mm#1{\\boldsymbol{#1}}$\n",
        "$\\def\\mb#1{\\mathbb{#1}}$\n",
        "$\\def\\c#1{\\mathcal{#1}}$\n",
        "$\\def\\mr#1{\\mathrm{#1}}$\n",
        "$\\newenvironment{rmat}{\\left[\\begin{array}{rrrrrrrrrrrrr}}{\\end{array}\\right]}$\n",
        "$\\newcommand\\brm{\\begin{rmat}}$\n",
        "$\\newcommand\\erm{\\end{rmat}}$\n",
        "$\\newenvironment{cmat}{\\left[\\begin{array}{ccccccccc}}{\\end{array}\\right]}$\n",
        "$\\newcommand\\bcm{\\begin{cmat}}$\n",
        "$\\newcommand\\ecm{\\end{cmat}}$\n",
        "\n",
        "\n",
        "# Homework 3\n",
        "## Homework guideline\n",
        "\n",
        "- The deadline is Oct 26th 10:30am. Submission after the deadline will not be graded. \n",
        "\n",
        "- Submit your work(your reasoning and your code) as a SINGLE .ipynb document. Please rename the document as _HW1_YOURNAME.ipynb_ (for example, _HW1_FELIX.ipynb_). You are responsible for checking that you have correctly submitted the correct document. If your code cannot run, you may receive NO point. \n",
        "\n",
        "- Please justify all short answers with a brief explanation. If you use latex command in the markdown, **2 points** bonus will be awarded.   \n",
        "\n",
        "- You only use the Python packages included in the following cell. You are not allowed to use other advanced package or modules unless you are permitted to. \n",
        "\n",
        "- In your final submission include the plots produced by the unedited code as presented below, as well as any additional plots produced after editing the code during the course of a problem. You may find it necessary to copy/paste relevant code into additional cells to accomplish this.\n",
        "\n",
        "- Feel free to use the lecture notes and other resources. But you\n",
        "must understand, write, and hand in your own answers. In addition, you must write and submit\n",
        "your own code in the programming part of the assignment (we may run your code).\n",
        "If you copy someone else homework solution, both of you may receive ZERO point. \n",
        "\n",
        "\n",
        "- Colab is preferred. However, if you use Anaconda, please download the .mat file locally and save it to the same folder as this homework file. "
      ],
      "metadata": {
        "id": "QWQdc24JNM3R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Collaboration:** List the names of all people you collaborated with and for which question(s). This is important!\n",
        "\n"
      ],
      "metadata": {
        "id": "FtsjeC1NL2Pn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Tips on Pandas Dataframe\n",
        "DataFrames are similar to Numpy arrays but more flexible;\n",
        "unlike Numpy arrays, they store row and column indices along with the values of the data. Each column of\n",
        "a DataFrame can also, in principle, store data of a different type. For this assignment, however, all data are\n",
        "floats. Here are a few commands that will get you working with Pandas for this assignment:\n",
        "\n",
        "|         |                                                       |\n",
        "|---------|-------------------------------------------------------|\n",
        "|df.head()    |# Print the first few lines of DataFrame df.                        |\n",
        "|df.index  | # Get the row indices for df.                   |\n",
        "|df.columns  |# Get the column indices.                                |\n",
        "|df['foo']    | # Return the column named ‘foo’.                                              |\n",
        "|df.drop(‘foo’, axis = 1)    |# Return all columns except ‘foo’.           |\n",
        "|df.values    |# Return the values as a Numpy array.                           |\n",
        "|df[‘foo’].values     |# Grab column foo and convert to Numpy array.                           |\n",
        "|df.iloc[:3,:3]    |# Use numerical indices (like Numpy) to get 3 rows and cols.                            |\n",
        "\n",
        "You may also refer to the following [cheat sheet](https://github.com/yexf308/MAT592/blob/main/Module0/pandas_cheat_sheet.pdf)."
      ],
      "metadata": {
        "id": "h9w_0JSM91kq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Q1: Bias-Variance trade-off (30pt)\n",
        "Let $\\mm\\theta\\in\\mb{R}^n$ be the unknown true means of our $n$ Gaussian distributions,i.e., we get a vector $\\m{X}$ where each $\\m{X}_i\\sim \\c{N}(\\theta_i, \\sigma^2), i=1,\\dots, n$. We assume every Gaussian distribution has the same variance and is independent, but means can be different. Our job is to find the estimator $\\hat{\\mm\\theta}$ to minimize the expected error $\\mb{E}[\\|\\hat{\\mm\\theta}-\\mm\\theta\\|_2^2]$.  All expectations are taken with respect to the random draws of the $\\m{X}_i$ random variables.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Q1.1 Derivation (10pt)\n",
        "**Show** the Bias-Variance trade-off formula for the estimator\n",
        "\\begin{align}\n",
        "\\mb{E}[\\|\\hat{\\mm\\theta}-\\mm\\theta\\|_2^2] = \\mb{V}[\\hat{\\mm\\theta}]+\\text{bias}^2[\\hat{\\mm\\theta}]\n",
        "\\end{align}\n",
        "where $\\mb{V}[\\hat{\\mm\\theta}] = \\mb{E}[\\|\\hat{\\mm\\theta} -\\mb{E}[\\hat{\\mm\\theta}]\\|_2^2]$ and $\\text{bias}^2[\\hat{\\mm\\theta}] = \\|\\mb{E}[\\hat{\\mm\\theta}-\\mm\\theta]\\|_2^2$"
      ],
      "metadata": {
        "id": "rA-oMYsONaR0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "0UyTo3HqKz4b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "If we only observe one data, which is just $\\m{X}$. Of course, the most natural choice of the estimator is $\\hat{\\mm\\theta}=\\m{X}$. Then $\\text{bias}[\\hat{\\mm\\theta}]=0$ and $\\mb{V}[\\hat{\\mm\\theta}] =n\\sigma^2 $. \n",
        "\n",
        "Let's try a different estimator. \n",
        "In class, we discussed the shrinkage estimation toward 0. Here we will shrink toward the mean of all of your data points, $\\bar{X}=\\frac{1}{n}\\sum_{i=1}^n \\m{X}_i$, i.e., \n",
        "\\begin{align}\n",
        "\\hat{\\mm\\theta} = (1-\\lambda) \\m{X} +\\lambda \\bar{X}\\mb{1}.\n",
        "\\end{align}\n",
        "where $\\mb{1}$ is the $n\\times 1$ vector of all 1's and $\\lambda$ is the real number between 0 and 1. \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Q1.2 Variance (6pt)\n",
        "What is the variance of the estimator $\\hat{\\mm\\theta}=(1-\\lambda)\\m{X}+\\lambda \\bar{X}\\mb{1}$?\n"
      ],
      "metadata": {
        "id": "SrmzT1ZtMz11"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "va6kpgcLXHqs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Q1.3 $\\text{Bias}^2$ (6pt)\n",
        "What is the $\\text{Bias}^2$ of the estimator $\\hat{\\mm\\theta}$? "
      ],
      "metadata": {
        "id": "md4CGDwdXOWU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "BYaly9wLXhRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Q1.4 Optimal $\\lambda$ (8pt)\n",
        "- What value of $\\lambda$ will result in the best estimator? \n",
        "\n",
        "- How much better compared to the natural estimator. \n",
        "\n",
        "- Describe how the optimal value of $\\lambda$ found changes if $\\frac{1}{n-1}\\sum_{i=1}^n (\\mm\\theta_i-\\bar{\\mm \\theta})^2 \\gg \\sigma^2$, $\\frac{1}{n-1}\\sum_{i=1}^n (\\mm\\theta_i-\\bar{\\mm \\theta})^2 \\approx \\sigma^2$, or $\\frac{1}{n-1}\\sum_{i=1}^n (\\mm\\theta_i-\\bar{\\mm \\theta})^2 \\ll \\sigma^2$?"
      ],
      "metadata": {
        "id": "ON_K73OkXiYC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "ZdxnLO6sX5ak"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Q2: USA Crime data (30pt)\n",
        "**Please read the problem description carefully.**\n",
        "\n",
        "### Data Set Description\n",
        "The following data consist of local crime statistics for 1994 US communities. We have split the dataset into a training and testing set with 1595 and 399 entries, respectively. We’d like to use\n",
        "this training set to fit a model to predict the crime rate in new communities and evaluate model performance on\n",
        "the test set. As there are a considerable number of input variables and fairly few training datapoints, overfitting\n",
        "is a serious issue. In order to avoid this, use the **stochastic coordinate descent LASSO algorithm**.\n",
        "\n",
        "The response $y$ is the rate of violent crimes\n",
        "reported per capita in a community. The name of the response variable is `ViolentCrimesPerPop`, and it is held\n",
        "in the first column of `df_train` and `df_test`. There are 95 features. These features include many variables.\n",
        "Some features are the consequence of complex political processes. Others\n",
        "are demographic characteristics of the community, including self-reported statistics about race, age, education,\n",
        "and employment drawn from Census reports. You may read the documentation for the original version of this dataset: http://archive.ics.uci.edu/ml/datasets/communities+and+crime. For example, `PctYoungKids2Par` represents percent of kids 4 and under in two parent households (numeric - decimal). \n",
        "\n",
        " Note **the features have been standardized to have mean 0 and variance 1**.\n",
        "\n",
        "The goals of this problem are twofold:\n",
        "- Think deeply about models you might train and\n",
        "how they might be misused.\n",
        "\n",
        "- See how Lasso encourages sparsity of linear models in settings where\n",
        "the feature set is very large relative to the number of training examples.\n",
        "\n",
        "We emphasize that training a\n",
        "model on this dataset can suggest a degree of correlation between a community’s demographics\n",
        "and the rate at which a community experiences and reports violent crime. We strongly encourage\n",
        "you to consider why these correlations may or may not hold more generally, whether correlations might\n",
        "result from a common cause, and what issues can result in misinterpreting what a model can explain.\n",
        " "
      ],
      "metadata": {
        "id": "OuC5PgDa9JNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/yexf308/AppliedStatistics/main/Homework/HW3/crime-train.txt?raw=true -O crime-train.txt\n",
        "!wget https://raw.githubusercontent.com/yexf308/AppliedStatistics/main/Homework/HW3/crime-test.txt?raw=true -O crime-test.txt"
      ],
      "metadata": {
        "id": "H2w78M_ADJQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_table(\"crime-train.txt\")\n",
        "df_test = pd.read_table(\"crime-test.txt\")"
      ],
      "metadata": {
        "id": "dxJ1yFHZDdiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "5T6O-FjIDe4l",
        "outputId": "52e848c0-a68d-4e15-f618-32810b10122b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ViolentCrimesPerPop  population  householdsize  agePct12t21  agePct12t29  \\\n",
              "0                 0.67       -0.45          -1.85        -1.06         0.67   \n",
              "1                 0.43       -0.45          -0.27        -0.22        -0.17   \n",
              "2                 0.12       -0.14           1.87         0.55         0.04   \n",
              "3                 0.03       -0.38           0.53        -0.28        -0.79   \n",
              "4                 0.14       -0.30          -1.12        -0.74        -0.10   \n",
              "\n",
              "   agePct16t24  agePct65up  numbUrban  pctUrban  medIncome  ...  NumStreet  \\\n",
              "0         0.08       -0.85      -0.34      0.68      -0.24  ...      -0.23   \n",
              "1        -0.34       -0.58      -0.50     -1.57      -0.29  ...      -0.23   \n",
              "2         0.02       -1.19      -0.03      0.68       1.05  ...      -0.23   \n",
              "3        -0.64       -0.35      -0.34      0.46       0.66  ...      -0.23   \n",
              "4        -0.40       -0.30      -0.19      0.68       0.76  ...      -0.23   \n",
              "\n",
              "   PctForeignBorn  PctBornSameState  PctSameHouse85  PctSameCity85  \\\n",
              "0           -0.02             -0.53           -1.08          -0.13   \n",
              "1           -0.33             -0.58            0.03           0.22   \n",
              "2           -0.11             -1.51            1.07           0.07   \n",
              "3           -0.46              0.54            0.58          -0.08   \n",
              "4            2.10             -0.92           -0.25           0.52   \n",
              "\n",
              "   PctSameState85  LandArea  PopDens  PctUsePubTrans  LemasPctOfficDrugUn  \n",
              "0           -0.66     -0.41    -0.56            1.26                -0.39  \n",
              "1           -0.46     -0.50    -0.11           -0.62                -0.39  \n",
              "2           -0.01     -0.41     0.77            0.52                -0.39  \n",
              "3           -0.61     -0.23    -0.70           -0.62                -0.39  \n",
              "4           -0.06     -0.50     1.71           -0.27                -0.39  \n",
              "\n",
              "[5 rows x 96 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d3ad3f67-a249-4623-a9b7-de554260ef96\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ViolentCrimesPerPop</th>\n",
              "      <th>population</th>\n",
              "      <th>householdsize</th>\n",
              "      <th>agePct12t21</th>\n",
              "      <th>agePct12t29</th>\n",
              "      <th>agePct16t24</th>\n",
              "      <th>agePct65up</th>\n",
              "      <th>numbUrban</th>\n",
              "      <th>pctUrban</th>\n",
              "      <th>medIncome</th>\n",
              "      <th>...</th>\n",
              "      <th>NumStreet</th>\n",
              "      <th>PctForeignBorn</th>\n",
              "      <th>PctBornSameState</th>\n",
              "      <th>PctSameHouse85</th>\n",
              "      <th>PctSameCity85</th>\n",
              "      <th>PctSameState85</th>\n",
              "      <th>LandArea</th>\n",
              "      <th>PopDens</th>\n",
              "      <th>PctUsePubTrans</th>\n",
              "      <th>LemasPctOfficDrugUn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.67</td>\n",
              "      <td>-0.45</td>\n",
              "      <td>-1.85</td>\n",
              "      <td>-1.06</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.08</td>\n",
              "      <td>-0.85</td>\n",
              "      <td>-0.34</td>\n",
              "      <td>0.68</td>\n",
              "      <td>-0.24</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.23</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.53</td>\n",
              "      <td>-1.08</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.66</td>\n",
              "      <td>-0.41</td>\n",
              "      <td>-0.56</td>\n",
              "      <td>1.26</td>\n",
              "      <td>-0.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.43</td>\n",
              "      <td>-0.45</td>\n",
              "      <td>-0.27</td>\n",
              "      <td>-0.22</td>\n",
              "      <td>-0.17</td>\n",
              "      <td>-0.34</td>\n",
              "      <td>-0.58</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-1.57</td>\n",
              "      <td>-0.29</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.23</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>-0.58</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.22</td>\n",
              "      <td>-0.46</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-0.11</td>\n",
              "      <td>-0.62</td>\n",
              "      <td>-0.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.12</td>\n",
              "      <td>-0.14</td>\n",
              "      <td>1.87</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-1.19</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>0.68</td>\n",
              "      <td>1.05</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.23</td>\n",
              "      <td>-0.11</td>\n",
              "      <td>-1.51</td>\n",
              "      <td>1.07</td>\n",
              "      <td>0.07</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.41</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.52</td>\n",
              "      <td>-0.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03</td>\n",
              "      <td>-0.38</td>\n",
              "      <td>0.53</td>\n",
              "      <td>-0.28</td>\n",
              "      <td>-0.79</td>\n",
              "      <td>-0.64</td>\n",
              "      <td>-0.35</td>\n",
              "      <td>-0.34</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.66</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.23</td>\n",
              "      <td>-0.46</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.58</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.61</td>\n",
              "      <td>-0.23</td>\n",
              "      <td>-0.70</td>\n",
              "      <td>-0.62</td>\n",
              "      <td>-0.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.14</td>\n",
              "      <td>-0.30</td>\n",
              "      <td>-1.12</td>\n",
              "      <td>-0.74</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.40</td>\n",
              "      <td>-0.30</td>\n",
              "      <td>-0.19</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.76</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.23</td>\n",
              "      <td>2.10</td>\n",
              "      <td>-0.92</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>0.52</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>1.71</td>\n",
              "      <td>-0.27</td>\n",
              "      <td>-0.39</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 96 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3ad3f67-a249-4623-a9b7-de554260ef96')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d3ad3f67-a249-4623-a9b7-de554260ef96 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d3ad3f67-a249-4623-a9b7-de554260ef96');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opLyP400irnG",
        "outputId": "69b15e98-7a1f-4ab9-912f-c0dbd8df087a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ViolentCrimesPerPop', 'population', 'householdsize', 'agePct12t21',\n",
              "       'agePct12t29', 'agePct16t24', 'agePct65up', 'numbUrban', 'pctUrban',\n",
              "       'medIncome', 'pctWWage', 'pctWFarmSelf', 'pctWInvInc', 'pctWSocSec',\n",
              "       'pctWPubAsst', 'pctWRetire', 'medFamInc', 'perCapInc', 'whitePerCap',\n",
              "       'blackPerCap', 'indianPerCap', 'AsianPerCap', 'HispPerCap',\n",
              "       'NumUnderPov', 'PctPopUnderPov', 'PctLess9thGrade', 'PctNotHSGrad',\n",
              "       'PctBSorMore', 'PctUnemployed', 'PctEmploy', 'PctEmplManu',\n",
              "       'PctEmplProfServ', 'PctOccupManu', 'PctOccupMgmtProf', 'MalePctDivorce',\n",
              "       'MalePctNevMarr', 'FemalePctDiv', 'TotalPctDiv', 'PersPerFam',\n",
              "       'PctFam2Par', 'PctKids2Par', 'PctYoungKids2Par', 'PctTeen2Par',\n",
              "       'PctWorkMomYoungKids', 'PctWorkMom', 'NumIlleg', 'PctIlleg', 'NumImmig',\n",
              "       'PctImmigRecent', 'PctImmigRec5', 'PctImmigRec8', 'PctImmigRec10',\n",
              "       'PctRecentImmig', 'PctRecImmig5', 'PctRecImmig8', 'PctRecImmig10',\n",
              "       'PctSpeakEnglOnly', 'PctNotSpeakEnglWell', 'PctLargHouseFam',\n",
              "       'PctLargHouseOccup', 'PersPerOccupHous', 'PersPerOwnOccHous',\n",
              "       'PersPerRentOccHous', 'PctPersOwnOccup', 'PctPersDenseHous',\n",
              "       'PctHousLess3BR', 'MedNumBR', 'HousVacant', 'PctHousOccup',\n",
              "       'PctHousOwnOcc', 'PctVacantBoarded', 'PctVacMore6Mos', 'MedYrHousBuilt',\n",
              "       'PctHousNoPhone', 'PctWOFullPlumb', 'OwnOccLowQuart', 'OwnOccMedVal',\n",
              "       'OwnOccHiQuart', 'RentLowQ', 'RentMedian', 'RentHighQ', 'MedRent',\n",
              "       'MedRentPctHousInc', 'MedOwnCostPctInc', 'MedOwnCostPctIncNoMtg',\n",
              "       'NumInShelters', 'NumStreet', 'PctForeignBorn', 'PctBornSameState',\n",
              "       'PctSameHouse85', 'PctSameCity85', 'PctSameState85', 'LandArea',\n",
              "       'PopDens', 'PctUsePubTrans', 'LemasPctOfficDrugUn'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Q2.1: *Result* rather than *Cause* (5pt)\n",
        "Before you train a model for this prediction task, **describe 3 features** in the dataset which might,\n",
        "if found to have nonzero weight in model, be interpreted as reasons for higher levels of violent crime, but\n",
        "which might actually be a *result* rather than (or in addition to being) the *cause* of this violence. "
      ],
      "metadata": {
        "id": "SAyL_ngslK0C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "HBOmwCTCldgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2.2: Stochastic coordinate descent LASSO algorithm (5pt)\n",
        "In class, we introduce the coordinate descent LASSO algorithm in the round robin way. We can also pick the coordinate randomly. \n",
        "\n",
        "**Algorithm:** To minimize function $\\ell(\\m{w})$\n",
        "\n",
        "Initialize $\\hat{\\m{w}}=0$ or smartly\n",
        "  - Precompute for all coordiate j\n",
        "     $$ a_j = \\m{X}_j^\\top \\m{X}_j $$\n",
        "  - While not converged\n",
        "   - Pick a coodinate j **uniformly at random**, compute\n",
        "\n",
        "     \\begin{align}\n",
        "     & c_j = \\m{X}_j^\\top (\\m{y}-\\m{X}_{-j}\\m{w}_{-j}) \\\\\n",
        "     & \\hat{w}_j = \\text{SoftThreshold}\\left(\\frac{c_j}{a_j},\\frac{\\lambda}{a_j}\\right)\n",
        "     \\end{align} \n",
        "\n",
        "Modify the LASSO code in class to stochastic coordinate descent LASSO algorithm.      "
      ],
      "metadata": {
        "id": "2HGwmsw9m2pN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2.2: Your code starts here"
      ],
      "metadata": {
        "id": "x1I9jbNNqpQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2.3 (Optional) Efficient LASSO Algorithm \n",
        "In fact, the current code is not efficient since it recalculate the same thing again and again in each iteration, which waste a lot of computational power. Please optimize your code, particularly in calculating `c_j` and `update`. Make sure test the correctness and efficiency in your new code. "
      ],
      "metadata": {
        "id": "cNNWvQuuszfO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2.3: Your code starts here"
      ],
      "metadata": {
        "id": "zi-k2Jxyt5ta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2.4: Training (15pt)\n",
        "- We will run the LASSO solver with $\\lambda=\\lambda_{\\max}$ defined above. \n",
        "- For the initial weights, just use 0. Then, cut\n",
        "$\\lambda$ down by a factor of 2 and run again, but this time pass in the values of $\\hat{\\m w}$ from your $\\lambda=\\lambda_{\\max}$ solution as\n",
        "your initial weights. This is faster than initializing with 0 weights each time.(You need to modify LASSO function accordingly, e.g., you can let initial weights as your input.) \n",
        "\n",
        "- Continue the process of cutting $\\lambda$ by a factor of 2 until the smallest value of $\\lambda$ is less than 0.01. Define “converging” as the change in any coefficient between one iteration and the next is no larger than $10^{-6}$. \n",
        "\n",
        "\n",
        "\n",
        "For all plots use a log-scale for $\\lambda$. You use `plt.xscale('log')`. \n",
        "- Plot the number of nonzeros of each solution versus $\\lambda$. \n",
        "\n",
        "- Plot the regularization paths (in one plot) for the coefficients for input features `agePct12t29`,\n",
        "`pctWSocSec`, `pctUrban`, `agePct65up`, and `householdsize`.\n",
        "\n",
        "- On one plot, plot the squared error on the training and test data versus $\\lambda$.\n",
        "\n",
        "- Sometimes a larger value of $\\lambda$ performs nearly as well as a smaller value, but a larger value will\n",
        "select fewer variables and perhaps be more interpretable. Inspect the weights (on features) for $\\lambda=30$. \n",
        "Which feature variable had the largest (most positive) Lasso coefficient? What about the most negative?\n",
        "Discuss briefly.\n"
      ],
      "metadata": {
        "id": "qCPC_t5zrYzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2.4: Your code starts here"
      ],
      "metadata": {
        "id": "43HwtPkLxHMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "AXe4endgxJGS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2.5: *Result* or *Cause* (5pt)\n",
        "Suppose there was a large negative weight on `agePct65up` and upon seeing this result, a politician\n",
        "suggests policies that encourage people over the age of 65 to move to high crime areas in an effort to reduce\n",
        "crime. What is the (statistical) flaw in this line of reasoning? (Hint: fire trucks are often seen around\n",
        "burning buildings, do fire trucks cause fire?)"
      ],
      "metadata": {
        "id": "EinT77ZJxY5r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "TfjD7z4JxoBK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Q3: Yelp Recruiting! (30pt)\n",
        "### Data Set Description\n",
        "We’ll now put the Lasso to work on some real even bigger data.  For many machine learning methods in general, one of the most important\n",
        "requirements for doing well is the ability to discover great features. \n",
        "\n",
        "Check it out first:  http://www.kaggle.com/c/yelp-recruiting. For this competition, the task is to predict the number of useful upvotes a particular review will receive. \n",
        "\n",
        "We can use our Lasso solver for this as\n",
        "follows. \n",
        "- First, generate a large amount of features from the data, even if many of them are likely unnecessary.\n",
        "\n",
        "- Afterward, use the Lasso to reduce the number of features to a more reasonable amount.\n",
        "\n",
        "Yelp provides a variety of data, such as the review’s text, date, and restaurant, as well as data pertaining to\n",
        "each business, user, and check-ins. This information has already been preprocessed for you into the following\n",
        "files:\n",
        "\n",
        "\n",
        "|         |                                                       |\n",
        "|---------|-------------------------------------------------------|\n",
        "|upvote_data.csv     |Data matrix for predicting number of useful votes                          |\n",
        "|upvote_labels.txt   |List of useful vote counts for each review                    |\n",
        "|upvote_features.txt  |Names of each feature for interpreting results                                    |\n",
        "|star_data.mtx      |Data matrix for predicting number of stars                                                    |\n",
        "|star_labels.txt     |List of number of stars given by each review             |\n",
        "|star_features.txt      |Names of each feature                               |\n",
        "\n",
        "\n",
        "For each task, data files contain data matrices, while labels are stored in separate text files. The first data\n",
        "matrix is stored in CSV format, each row corresponding to one review. The second data matrix is stored\n",
        "in Matrix Market Format, a format for sparse matrices. Meta information for each feature is provided in\n",
        "the final text files, one feature per line. For the upvote task, these are functions of various data attributes.\n",
        "For the stars task, these are strings of one, two, or three words (n-grams). The feature values correspond\n",
        "roughly to how often each word appears in the review. All columns have also been normalized.\n"
      ],
      "metadata": {
        "id": "kceDm2iPbLDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/yexf308/AppliedStatistics/main/Homework/HW3/upvote_labels.txt?raw=true -O upvote_labels.txt\n",
        "!wget https://raw.githubusercontent.com/yexf308/AppliedStatistics/main/Homework/HW3/upvote_features.txt?raw=true -O upvote_features.txt\n",
        "!wget https://raw.githubusercontent.com/yexf308/AppliedStatistics/main/Homework/HW3/upvote_data.csv?raw=true -O upvote_data.csv"
      ],
      "metadata": {
        "id": "q-lqXO5yiKFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a text file of integers:\n",
        "y = np.loadtxt(\"upvote_labels.txt\", dtype=int)\n",
        "# Load a text file of strings:\n",
        "featureNames = open(\"upvote_features.txt\").read().splitlines()\n",
        "# Load a csv of floats:\n",
        "A = np.genfromtxt(\"upvote_data.csv\", delimiter=\",\")\n"
      ],
      "metadata": {
        "id": "CoSK2RQwji4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y.shape)\n",
        "print(len(featureNames))\n",
        "print(A.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbuzryInjpMm",
        "outputId": "3d0340ec-9b3e-4867-847a-774619c7863e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6000,)\n",
            "1000\n",
            "(6000, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this part of the problem, you have the following tasks:\n",
        "\n",
        "---\n",
        "### Q3.1 Training (20pt)\n",
        "- Solve lasso to predict the number of useful votes a Yelp review will receive. In the matrix $A$, Use the first\n",
        "4000 samples for training, the next 1000 samples for validation, and the remaining samples for testing.\n",
        "\n",
        "- Starting the maximum possible $\\lambda$, run Lasso on the training set, decreasing $\\lambda$ using previous solutions as initial conditions to each problem. Stop when you have considered enough $\\lambda$'s that, based on validation error, you\n",
        "can choose a good solution with confidence (for instance, when validation error begins increasing or\n",
        "stops decreasing significant).  At each solution, record the mean squared error (MSE) on training\n",
        "and validation data. In addition, record the number of nonzeros in each solution."
      ],
      "metadata": {
        "id": "zriI7cHBkuQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q3.1: Your code starts here"
      ],
      "metadata": {
        "id": "uEFN8maWzAYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Q3.2 Find optimal $\\lambda$ (5pt)\n",
        "Find the $\\lambda$ that achieves best validation performance, and test your model on the remaining\n",
        "set of test data. What MSE value do you get? "
      ],
      "metadata": {
        "id": "Svb8PH__zJH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q3.2: Your code starts here"
      ],
      "metadata": {
        "id": "cOqc3VzRzcH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "XYEssLx-zfME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Q3.3 Find most important features (5pt)\n",
        "Inspect your solution and take a look at the 10 features with weights largest in magnitude.\n",
        "List the names of these features and their weights, and comment on if the weights generally make sense\n",
        "intuitively."
      ],
      "metadata": {
        "id": "JnCryh6pzxO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q3.3: Your code starts here"
      ],
      "metadata": {
        "id": "OiWuZFdk0CIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "43_949cS0EL_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Q3.4 (optional) Predict star labels\n",
        "Let's work on even larger data.\n",
        "\n",
        "Repeat part 1, 2, 3 using the data matrix and labels for predicting the score of a review.\n",
        "Use the first 30,000 examples for training and divide the remaining samples between validation and\n",
        "testing as before.\n",
        "\n",
        "**Note:** this time the dataset is much larger, you need to optimize your code wisely. "
      ],
      "metadata": {
        "id": "xE2WmZlg1hf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/yexf308/AppliedStatistics/main/Homework/HW3/star_data.mtx?raw=true -O star_data.mtx\n",
        "!wget https://raw.githubusercontent.com/yexf308/AppliedStatistics/main/Homework/HW3/star_features.txt?raw=true -O star_features.txt\n",
        "!wget https://raw.githubusercontent.com/yexf308/AppliedStatistics/main/Homework/HW3/star_labels.txt?raw=true -O star_labels.txt"
      ],
      "metadata": {
        "id": "24N3Zkis1Mjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a matrix market matrix, convert it to csc format:\n",
        "B = io.mmread(\"star_data.mtx\").tocsc()\n",
        "featureNames_star = open(\"star_features.txt\").read().splitlines()\n",
        "y_star = np.loadtxt(\"star_labels.txt\", dtype=int)"
      ],
      "metadata": {
        "id": "liee0RGf1yDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(B.shape)\n",
        "print(len(featureNames_star))\n",
        "print(y_star.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jf6sFPe3Mrw",
        "outputId": "e129eecb-ab36-4033-d38b-1bc720a7d2ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(45000, 2500)\n",
            "2500\n",
            "(45000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q3.4: Your code starts here"
      ],
      "metadata": {
        "id": "kwmFlOBR3zUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "arnRN5R73LTQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Q4: Reducing elastic net to lasso (10pt)\n",
        "The objective function in elastic net is \n",
        "\\begin{align}\n",
        "\\ell_1(\\m{w},\\lambda_1, \\lambda_2) = \\|\\m{y}-\\m{X}\\m{w}\\|_2^2+\\lambda_2\\|\\m{w}\\|_2^2+\\lambda_1\\|\\m{w}\\|_1\n",
        "\\end{align}\n",
        "and the objective function in lasso is \n",
        "\\begin{align}\n",
        "\\ell_2(\\m{w},\\lambda_1) = \\|\\tilde{\\m{y}}-\\tilde{\\m{X}}\\m{w}\\|_2^2+c\\lambda_1\\|\\m{w}\\|_1\n",
        "\\end{align}\n",
        "where $c=(1+\\lambda_2)^{-1/2}$ and \n",
        "\\begin{align}\n",
        "\\tilde{\\m{X}} = c\\bcm \\m{X} \\\\\\sqrt{\\lambda_2} \\m{I}_d \\ecm, \\qquad \\tilde{\\m y} = \\bcm \\m{y} \\\\ \\m{0}\\ecm \n",
        "\\end{align}\n",
        "\n",
        "**Show** \n",
        "\\begin{align}\n",
        "\\arg\\min \\ell_1(\\m{w},\\lambda_1,\\lambda_2) = c(\\arg\\min \\ell_2(\\m{w},\\lambda_1))\n",
        "\\end{align}\n",
        "i.e., $\\ell_1(c\\m{w})=\\ell_2(\\m{w})$. \n",
        "So one can solve an elastic net problem using a lasso solver on modified data."
      ],
      "metadata": {
        "id": "aDcfrBq81oBX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution: "
      ],
      "metadata": {
        "id": "FENPipjx4tm1"
      }
    }
  ]
}