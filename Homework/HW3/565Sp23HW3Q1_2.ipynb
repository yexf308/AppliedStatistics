{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKY0XvnNqoylj2dnNE15pg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yexf308/AppliedStatistics/blob/main/Homework/HW3/565Sp23HW3Q1_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lRxrr9CMy-N",
        "outputId": "b5373643-8d64-49f8-9c4d-9ca190157e23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        }
      ],
      "source": [
        "%pylab inline \n",
        "import pandas as pd\n",
        "from scipy import linalg\n",
        "from itertools import combinations\n",
        "import scipy\n",
        "import scipy.io as io\n",
        "import scipy.sparse as sparse"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\def\\m#1{\\mathbf{#1}}$\n",
        "$\\def\\mm#1{\\boldsymbol{#1}}$\n",
        "$\\def\\mb#1{\\mathbb{#1}}$\n",
        "$\\def\\c#1{\\mathcal{#1}}$\n",
        "$\\def\\mr#1{\\mathrm{#1}}$\n",
        "$\\newenvironment{rmat}{\\left[\\begin{array}{rrrrrrrrrrrrr}}{\\end{array}\\right]}$\n",
        "$\\newcommand\\brm{\\begin{rmat}}$\n",
        "$\\newcommand\\erm{\\end{rmat}}$\n",
        "$\\newenvironment{cmat}{\\left[\\begin{array}{ccccccccc}}{\\end{array}\\right]}$\n",
        "$\\newcommand\\bcm{\\begin{cmat}}$\n",
        "$\\newcommand\\ecm{\\end{cmat}}$\n",
        "\n",
        "\n",
        "# Homework 3\n",
        "## Homework guideline\n",
        "\n",
        "- The deadline is March 31st 10:30am. Submission after the deadline will not be graded. \n",
        "\n",
        "- Submit your work(your reasoning and your code) as a SINGLE .ipynb document. Please rename the document as _HW1_YOURNAME.ipynb_ (for example, _HW1_FELIX.ipynb_). You are responsible for checking that you have correctly submitted the correct document. If your code cannot run, you may receive NO point. \n",
        "\n",
        "- Please justify all short answers with a brief explanation. If you use latex command in the markdown, **2 points** bonus will be awarded.   \n",
        "\n",
        "- You only use the Python packages included in the following cell. You are not allowed to use other advanced package or modules unless you are permitted to. \n",
        "\n",
        "- In your final submission include the plots produced by the unedited code as presented below, as well as any additional plots produced after editing the code during the course of a problem. You may find it necessary to copy/paste relevant code into additional cells to accomplish this.\n",
        "\n",
        "- Feel free to use the lecture notes and other resources. But you\n",
        "must understand, write, and hand in your own answers. In addition, you must write and submit\n",
        "your own code in the programming part of the assignment (we may run your code).\n",
        "If you copy someone else homework solution, both of you may receive ZERO point. \n",
        "\n",
        "\n",
        "- Colab is preferred. However, if you use Anaconda, please download the .mat file locally and save it to the same folder as this homework file. "
      ],
      "metadata": {
        "id": "QWQdc24JNM3R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Collaboration:** List the names of all people you collaborated with and for which question(s). This is important!\n",
        "\n"
      ],
      "metadata": {
        "id": "FtsjeC1NL2Pn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Tips on Pandas Dataframe\n",
        "DataFrames are similar to Numpy arrays but more flexible;\n",
        "unlike Numpy arrays, they store row and column indices along with the values of the data. Each column of\n",
        "a DataFrame can also, in principle, store data of a different type. For this assignment, however, all data are\n",
        "floats. Here are a few commands that will get you working with Pandas for this assignment:\n",
        "\n",
        "|         |                                                       |\n",
        "|---------|-------------------------------------------------------|\n",
        "|df.head()    |# Print the first few lines of DataFrame df.                        |\n",
        "|df.index  | # Get the row indices for df.                   |\n",
        "|df.columns  |# Get the column indices.                                |\n",
        "|df['foo']    | # Return the column named ‘foo’.                                              |\n",
        "|df.drop(‘foo’, axis = 1)    |# Return all columns except ‘foo’.           |\n",
        "|df.values    |# Return the values as a Numpy array.                           |\n",
        "|df[‘foo’].values     |# Grab column foo and convert to Numpy array.                           |\n",
        "|df.iloc[:3,:3]    |# Use numerical indices (like Numpy) to get 3 rows and cols.                            |\n",
        "\n",
        "You may also refer to the following [cheat sheet](https://github.com/yexf308/MAT592/blob/main/Module0/pandas_cheat_sheet.pdf)."
      ],
      "metadata": {
        "id": "h9w_0JSM91kq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Q1: Bias-Variance trade-off (30pt)\n",
        "Let $\\mm\\theta\\in\\mb{R}^n$ be the unknown true means of our $n$ Gaussian distributions,i.e., we get a vector $\\m{X}$ where each $\\m{X}_i\\sim \\c{N}(\\theta_i, \\sigma^2), i=1,\\dots, n$. We assume every Gaussian distribution has the same variance and is independent, but means can be different. Our job is to find the estimator $\\hat{\\mm\\theta}$ to minimize the expected error $\\mb{E}[\\|\\hat{\\mm\\theta}-\\mm\\theta\\|_2^2]$.  All expectations are taken with respect to the random draws of the $\\m{X}_i$ random variables.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Q1.1 Derivation (10pt)\n",
        "**Show** the Bias-Variance trade-off formula for the estimator\n",
        "\\begin{align}\n",
        "\\mb{E}[\\|\\hat{\\mm\\theta}-\\mm\\theta\\|_2^2] = \\mb{V}[\\hat{\\mm\\theta}]+\\text{bias}^2[\\hat{\\mm\\theta}]\n",
        "\\end{align}\n",
        "where $\\mb{V}[\\hat{\\mm\\theta}] = \\mb{E}[\\|\\hat{\\mm\\theta} -\\mb{E}[\\hat{\\mm\\theta}]\\|_2^2]$ and $\\text{bias}^2[\\hat{\\mm\\theta}] = \\|\\mb{E}[\\hat{\\mm\\theta}-\\mm\\theta]\\|_2^2$"
      ],
      "metadata": {
        "id": "rA-oMYsONaR0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "0UyTo3HqKz4b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "If we only observe one data, which is just $\\m{X}$. Of course, the most natural choice of the estimator is $\\hat{\\mm\\theta}=\\m{X}$. \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Q1.2 $\\text{Bias}^2$ and Variance for natural estimator (8pt)\n",
        "What is the $\\text{Bias}^2$ and variance of the natural estimator $\\hat{\\mm\\theta}=\\m{X}$?\n"
      ],
      "metadata": {
        "id": "SrmzT1ZtMz11"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "va6kpgcLXHqs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Let's try a different estimator, shrinkage estimator, $\\hat{\\mm\\theta}=\\frac{9}{10}\\m{X}$ \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Q1.3 $\\text{Bias}^2$ and Variance for shrinkage estimator (8pt)\n",
        "What is the $\\text{Bias}^2$ and variance of the shrinkage estimator $\\hat{\\mm\\theta}=\\frac{9}{10}\\m{X}$?\n"
      ],
      "metadata": {
        "id": "md4CGDwdXOWU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "BYaly9wLXhRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Q1.4 Which one is better? (4pt)\n",
        "Suppose you know that the variance of our samples is quite a bit. Specifically assume $\\sigma^2>\\frac{1}{10}\\theta_i^2$ for all $i$. Which estimator is better?"
      ],
      "metadata": {
        "id": "ON_K73OkXiYC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "ZdxnLO6sX5ak"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Q2: USA Crime data (30pt)\n",
        "**This problem can be used to present in showcase day as extra credits.**\n",
        "\n",
        "\n",
        "**Please read the problem description carefully.**\n",
        "\n",
        "### Data Set Description\n",
        "The following data consist of local crime statistics for 1994 US communities. We have split the dataset into a training and testing set with 1595 and 399 entries, respectively. We’d like to use\n",
        "this training set to fit a model to predict the crime rate in new communities and evaluate model performance on\n",
        "the test set. As there are a considerable number of input variables and fairly few training datapoints, overfitting\n",
        "is a serious issue. In order to avoid this, use the **stochastic coordinate descent LASSO algorithm**.\n",
        "\n",
        "The response $y$ is the rate of violent crimes\n",
        "reported per capita in a community. The name of the response variable is `ViolentCrimesPerPop`, and it is held\n",
        "in the first column of `df_train` and `df_test`. There are 95 features. These features include many variables.\n",
        "Some features are the consequence of complex political processes. Others\n",
        "are demographic characteristics of the community, including self-reported statistics about race, age, education,\n",
        "and employment drawn from Census reports. You may read the documentation for the original version of this dataset: http://archive.ics.uci.edu/ml/datasets/communities+and+crime. For example, `PctYoungKids2Par` represents percent of kids 4 and under in two parent households (numeric - decimal). \n",
        "\n",
        " Note **the features have been standardized to have mean 0 and variance 1**.\n",
        "\n",
        "The goals of this problem are twofold:\n",
        "- Think deeply about models you might train and\n",
        "how they might be misused.\n",
        "\n",
        "- See how Lasso encourages sparsity of linear models in settings where\n",
        "the feature set is very large relative to the number of training examples.\n",
        "\n",
        "We emphasize that training a\n",
        "model on this dataset can suggest a degree of correlation between a community’s demographics\n",
        "and the rate at which a community experiences and reports violent crime. We strongly encourage\n",
        "you to consider why these correlations may or may not hold more generally, whether correlations might\n",
        "result from a common cause, and what issues can result in misinterpreting what a model can explain.\n",
        " "
      ],
      "metadata": {
        "id": "OuC5PgDa9JNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/yexf308/AppliedStatistics/main/Homework/HW3/crime-train.txt?raw=true -O crime-train.txt\n",
        "!wget https://raw.githubusercontent.com/yexf308/AppliedStatistics/main/Homework/HW3/crime-test.txt?raw=true -O crime-test.txt"
      ],
      "metadata": {
        "id": "H2w78M_ADJQ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e978684-b4ca-45a9-b7a6-85f4b9531e41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-19 16:34:21--  https://raw.githubusercontent.com/yexf308/AppliedStatistics/main/Homework/HW3/crime-train.txt?raw=true\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 855572 (836K) [text/plain]\n",
            "Saving to: ‘crime-train.txt’\n",
            "\n",
            "crime-train.txt     100%[===================>] 835.52K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2022-10-19 16:34:21 (28.3 MB/s) - ‘crime-train.txt’ saved [855572/855572]\n",
            "\n",
            "--2022-10-19 16:34:21--  https://raw.githubusercontent.com/yexf308/AppliedStatistics/main/Homework/HW3/crime-test.txt?raw=true\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 214736 (210K) [text/plain]\n",
            "Saving to: ‘crime-test.txt’\n",
            "\n",
            "crime-test.txt      100%[===================>] 209.70K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-10-19 16:34:22 (10.8 MB/s) - ‘crime-test.txt’ saved [214736/214736]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_table(\"crime-train.txt\")\n",
        "df_test = pd.read_table(\"crime-test.txt\")"
      ],
      "metadata": {
        "id": "dxJ1yFHZDdiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "5T6O-FjIDe4l",
        "outputId": "f04f9307-15ab-4d7c-e9db-a91f6460adc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ViolentCrimesPerPop  population  householdsize  agePct12t21  agePct12t29  \\\n",
              "0                 0.67       -0.45          -1.85        -1.06         0.67   \n",
              "1                 0.43       -0.45          -0.27        -0.22        -0.17   \n",
              "2                 0.12       -0.14           1.87         0.55         0.04   \n",
              "3                 0.03       -0.38           0.53        -0.28        -0.79   \n",
              "4                 0.14       -0.30          -1.12        -0.74        -0.10   \n",
              "\n",
              "   agePct16t24  agePct65up  numbUrban  pctUrban  medIncome  ...  NumStreet  \\\n",
              "0         0.08       -0.85      -0.34      0.68      -0.24  ...      -0.23   \n",
              "1        -0.34       -0.58      -0.50     -1.57      -0.29  ...      -0.23   \n",
              "2         0.02       -1.19      -0.03      0.68       1.05  ...      -0.23   \n",
              "3        -0.64       -0.35      -0.34      0.46       0.66  ...      -0.23   \n",
              "4        -0.40       -0.30      -0.19      0.68       0.76  ...      -0.23   \n",
              "\n",
              "   PctForeignBorn  PctBornSameState  PctSameHouse85  PctSameCity85  \\\n",
              "0           -0.02             -0.53           -1.08          -0.13   \n",
              "1           -0.33             -0.58            0.03           0.22   \n",
              "2           -0.11             -1.51            1.07           0.07   \n",
              "3           -0.46              0.54            0.58          -0.08   \n",
              "4            2.10             -0.92           -0.25           0.52   \n",
              "\n",
              "   PctSameState85  LandArea  PopDens  PctUsePubTrans  LemasPctOfficDrugUn  \n",
              "0           -0.66     -0.41    -0.56            1.26                -0.39  \n",
              "1           -0.46     -0.50    -0.11           -0.62                -0.39  \n",
              "2           -0.01     -0.41     0.77            0.52                -0.39  \n",
              "3           -0.61     -0.23    -0.70           -0.62                -0.39  \n",
              "4           -0.06     -0.50     1.71           -0.27                -0.39  \n",
              "\n",
              "[5 rows x 96 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc967a95-c311-4cbe-bfa4-ed5067634a0a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ViolentCrimesPerPop</th>\n",
              "      <th>population</th>\n",
              "      <th>householdsize</th>\n",
              "      <th>agePct12t21</th>\n",
              "      <th>agePct12t29</th>\n",
              "      <th>agePct16t24</th>\n",
              "      <th>agePct65up</th>\n",
              "      <th>numbUrban</th>\n",
              "      <th>pctUrban</th>\n",
              "      <th>medIncome</th>\n",
              "      <th>...</th>\n",
              "      <th>NumStreet</th>\n",
              "      <th>PctForeignBorn</th>\n",
              "      <th>PctBornSameState</th>\n",
              "      <th>PctSameHouse85</th>\n",
              "      <th>PctSameCity85</th>\n",
              "      <th>PctSameState85</th>\n",
              "      <th>LandArea</th>\n",
              "      <th>PopDens</th>\n",
              "      <th>PctUsePubTrans</th>\n",
              "      <th>LemasPctOfficDrugUn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.67</td>\n",
              "      <td>-0.45</td>\n",
              "      <td>-1.85</td>\n",
              "      <td>-1.06</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.08</td>\n",
              "      <td>-0.85</td>\n",
              "      <td>-0.34</td>\n",
              "      <td>0.68</td>\n",
              "      <td>-0.24</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.23</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.53</td>\n",
              "      <td>-1.08</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.66</td>\n",
              "      <td>-0.41</td>\n",
              "      <td>-0.56</td>\n",
              "      <td>1.26</td>\n",
              "      <td>-0.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.43</td>\n",
              "      <td>-0.45</td>\n",
              "      <td>-0.27</td>\n",
              "      <td>-0.22</td>\n",
              "      <td>-0.17</td>\n",
              "      <td>-0.34</td>\n",
              "      <td>-0.58</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-1.57</td>\n",
              "      <td>-0.29</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.23</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>-0.58</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.22</td>\n",
              "      <td>-0.46</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-0.11</td>\n",
              "      <td>-0.62</td>\n",
              "      <td>-0.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.12</td>\n",
              "      <td>-0.14</td>\n",
              "      <td>1.87</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-1.19</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>0.68</td>\n",
              "      <td>1.05</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.23</td>\n",
              "      <td>-0.11</td>\n",
              "      <td>-1.51</td>\n",
              "      <td>1.07</td>\n",
              "      <td>0.07</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.41</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.52</td>\n",
              "      <td>-0.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03</td>\n",
              "      <td>-0.38</td>\n",
              "      <td>0.53</td>\n",
              "      <td>-0.28</td>\n",
              "      <td>-0.79</td>\n",
              "      <td>-0.64</td>\n",
              "      <td>-0.35</td>\n",
              "      <td>-0.34</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.66</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.23</td>\n",
              "      <td>-0.46</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.58</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.61</td>\n",
              "      <td>-0.23</td>\n",
              "      <td>-0.70</td>\n",
              "      <td>-0.62</td>\n",
              "      <td>-0.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.14</td>\n",
              "      <td>-0.30</td>\n",
              "      <td>-1.12</td>\n",
              "      <td>-0.74</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.40</td>\n",
              "      <td>-0.30</td>\n",
              "      <td>-0.19</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.76</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.23</td>\n",
              "      <td>2.10</td>\n",
              "      <td>-0.92</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>0.52</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>1.71</td>\n",
              "      <td>-0.27</td>\n",
              "      <td>-0.39</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 96 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc967a95-c311-4cbe-bfa4-ed5067634a0a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bc967a95-c311-4cbe-bfa4-ed5067634a0a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bc967a95-c311-4cbe-bfa4-ed5067634a0a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opLyP400irnG",
        "outputId": "4e842df3-8172-49aa-9d4e-e3366f51d10a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ViolentCrimesPerPop', 'population', 'householdsize', 'agePct12t21',\n",
              "       'agePct12t29', 'agePct16t24', 'agePct65up', 'numbUrban', 'pctUrban',\n",
              "       'medIncome', 'pctWWage', 'pctWFarmSelf', 'pctWInvInc', 'pctWSocSec',\n",
              "       'pctWPubAsst', 'pctWRetire', 'medFamInc', 'perCapInc', 'whitePerCap',\n",
              "       'blackPerCap', 'indianPerCap', 'AsianPerCap', 'HispPerCap',\n",
              "       'NumUnderPov', 'PctPopUnderPov', 'PctLess9thGrade', 'PctNotHSGrad',\n",
              "       'PctBSorMore', 'PctUnemployed', 'PctEmploy', 'PctEmplManu',\n",
              "       'PctEmplProfServ', 'PctOccupManu', 'PctOccupMgmtProf', 'MalePctDivorce',\n",
              "       'MalePctNevMarr', 'FemalePctDiv', 'TotalPctDiv', 'PersPerFam',\n",
              "       'PctFam2Par', 'PctKids2Par', 'PctYoungKids2Par', 'PctTeen2Par',\n",
              "       'PctWorkMomYoungKids', 'PctWorkMom', 'NumIlleg', 'PctIlleg', 'NumImmig',\n",
              "       'PctImmigRecent', 'PctImmigRec5', 'PctImmigRec8', 'PctImmigRec10',\n",
              "       'PctRecentImmig', 'PctRecImmig5', 'PctRecImmig8', 'PctRecImmig10',\n",
              "       'PctSpeakEnglOnly', 'PctNotSpeakEnglWell', 'PctLargHouseFam',\n",
              "       'PctLargHouseOccup', 'PersPerOccupHous', 'PersPerOwnOccHous',\n",
              "       'PersPerRentOccHous', 'PctPersOwnOccup', 'PctPersDenseHous',\n",
              "       'PctHousLess3BR', 'MedNumBR', 'HousVacant', 'PctHousOccup',\n",
              "       'PctHousOwnOcc', 'PctVacantBoarded', 'PctVacMore6Mos', 'MedYrHousBuilt',\n",
              "       'PctHousNoPhone', 'PctWOFullPlumb', 'OwnOccLowQuart', 'OwnOccMedVal',\n",
              "       'OwnOccHiQuart', 'RentLowQ', 'RentMedian', 'RentHighQ', 'MedRent',\n",
              "       'MedRentPctHousInc', 'MedOwnCostPctInc', 'MedOwnCostPctIncNoMtg',\n",
              "       'NumInShelters', 'NumStreet', 'PctForeignBorn', 'PctBornSameState',\n",
              "       'PctSameHouse85', 'PctSameCity85', 'PctSameState85', 'LandArea',\n",
              "       'PopDens', 'PctUsePubTrans', 'LemasPctOfficDrugUn'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Q2.1: *Result* rather than *Cause* (5pt)\n",
        "Before you train a model for this prediction task, **describe 3 features** in the dataset which might,\n",
        "if found to have nonzero weight in model, be interpreted as reasons for higher levels of violent crime, but\n",
        "which might actually be a *result* rather than (or in addition to being) the *cause* of this violence. "
      ],
      "metadata": {
        "id": "SAyL_ngslK0C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "HBOmwCTCldgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Q2.2: Stochastic coordinate descent LASSO algorithm (5pt)\n",
        "In class, we introduce the coordinate descent LASSO algorithm in the round robin way. We can also pick the coordinate randomly. \n",
        "\n",
        "**Algorithm:** To minimize function $\\ell(\\m{w})$\n",
        "\n",
        "Initialize $\\hat{\\m{w}}=0$ or smartly\n",
        "  - Precompute for all coordiate j\n",
        "     $$ a_j = \\m{X}_j^\\top \\m{X}_j $$\n",
        "  - While not converged\n",
        "   - Pick a coodinate j **uniformly at random**, compute\n",
        "\n",
        "     \\begin{align}\n",
        "     & c_j = \\m{X}_j^\\top (\\m{y}-\\m{X}_{-j}\\m{w}_{-j}) \\\\\n",
        "     & \\hat{w}_j = \\text{SoftThreshold}\\left(\\frac{c_j}{a_j},\\frac{\\lambda}{a_j}\\right)\n",
        "     \\end{align} \n",
        "\n",
        "Modify the LASSO code in class to stochastic coordinate descent LASSO algorithm.      "
      ],
      "metadata": {
        "id": "2HGwmsw9m2pN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2.2: Your code starts here\n",
        "X = df_train.drop('ViolentCrimesPerPop', axis=1)\n",
        "y = df_train['ViolentCrimesPerPop']\n",
        "# print(X.shape, y.shape)\n",
        "\n",
        "X_test = df_test.drop('ViolentCrimesPerPop', axis=1)\n",
        "y_test = df_test['ViolentCrimesPerPop']"
      ],
      "metadata": {
        "id": "x1I9jbNNqpQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Q2.3 (Optional) Efficient LASSO Algorithm \n",
        "In fact, the current code is not efficient since it recalculate the same thing again and again in each iteration, which waste a lot of computational power. Please optimize your code, particularly in calculating `c_j` and `update`. Make sure test the correctness and efficiency in your new code. "
      ],
      "metadata": {
        "id": "cNNWvQuuszfO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2.3: Your code starts here"
      ],
      "metadata": {
        "id": "zi-k2Jxyt5ta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Q2.4: Training (15pt)\n",
        "- We will run the LASSO solver with $\\lambda=\\lambda_{\\max}$ defined above. \n",
        "- For the initial weights, just use 0. Then, cut\n",
        "$\\lambda$ down by a factor of 2 and run again, but this time pass in the values of $\\hat{\\m w}$ from your $\\lambda=\\lambda_{\\max}$ solution as\n",
        "your initial weights. This is faster than initializing with 0 weights each time.(You need to modify LASSO function accordingly, e.g., you can let initial weights as your input.) \n",
        "\n",
        "- Continue the process of cutting $\\lambda$ by a factor of 2 until the smallest value of $\\lambda$ is less than 0.01. Define “converging” as the change in any coefficient between one iteration and the next is no larger than $10^{-6}$. \n",
        "\n",
        "\n",
        "\n",
        "For all plots use a log-scale for $\\lambda$. You use `plt.xscale('log')`. \n",
        "- Plot the number of nonzeros of each solution versus $\\lambda$. \n",
        "\n",
        "- Plot the regularization paths (in one plot) for the coefficients for input features `agePct12t29`,\n",
        "`pctWSocSec`, `pctUrban`, `agePct65up`, and `householdsize`.\n",
        "\n",
        "- On one plot, plot the squared error on the training and test data versus $\\lambda$.\n",
        "\n",
        "- Sometimes a larger value of $\\lambda$ performs nearly as well as a smaller value, but a larger value will\n",
        "select fewer variables and perhaps be more interpretable. Inspect the weights (on features) for $\\lambda=30$. \n",
        "Which feature variable had the largest (most positive) Lasso coefficient? What about the most negative?\n",
        "Discuss briefly.\n"
      ],
      "metadata": {
        "id": "qCPC_t5zrYzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2.4: Your code starts here"
      ],
      "metadata": {
        "id": "43HwtPkLxHMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "AXe4endgxJGS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Q2.5: *Result* or *Cause* (5pt)\n",
        "Suppose there was a large negative weight on `agePct65up` and upon seeing this result, a politician\n",
        "suggests policies that encourage people over the age of 65 to move to high crime areas in an effort to reduce\n",
        "crime. What is the (statistical) flaw in this line of reasoning? (Hint: fire trucks are often seen around\n",
        "burning buildings, do fire trucks cause fire?)"
      ],
      "metadata": {
        "id": "EinT77ZJxY5r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "TfjD7z4JxoBK"
      }
    }
  ]
}