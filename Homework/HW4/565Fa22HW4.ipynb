{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "565Fa22HW4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOSqAF1hpGlFubBxdRXJGMg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yexf308/AppliedStatistics/blob/main/Homework/HW4/565Fa22HW4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIF8inxrMMKO",
        "outputId": "466bb196-6646-4453-df03-70068d11e68e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['linalg', 'clf']\n",
            "`%matplotlib` prevents importing * from pylab and numpy\n",
            "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
          ]
        }
      ],
      "source": [
        "%pylab inline \n",
        "import pandas as pd\n",
        "from scipy import linalg\n",
        "from sklearn import tree\n",
        "from itertools import combinations\n",
        "import scipy\n",
        "import scipy.io as io\n",
        "from scipy.io import mmread\n",
        "import scipy.sparse as sparse"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\def\\m#1{\\mathbf{#1}}$\n",
        "$\\def\\mm#1{\\boldsymbol{#1}}$\n",
        "$\\def\\mb#1{\\mathbb{#1}}$\n",
        "$\\def\\c#1{\\mathcal{#1}}$\n",
        "$\\def\\mr#1{\\mathrm{#1}}$\n",
        "$\\newenvironment{rmat}{\\left[\\begin{array}{rrrrrrrrrrrrr}}{\\end{array}\\right]}$\n",
        "$\\newcommand\\brm{\\begin{rmat}}$\n",
        "$\\newcommand\\erm{\\end{rmat}}$\n",
        "$\\newenvironment{cmat}{\\left[\\begin{array}{ccccccccc}}{\\end{array}\\right]}$\n",
        "$\\newcommand\\bcm{\\begin{cmat}}$\n",
        "$\\newcommand\\ecm{\\end{cmat}}$\n",
        "# Homework 4\n",
        "## Homework guideline\n",
        "- The deadline is Nov 18th 10:30am. Submission after the deadline will not be graded. \n",
        "\n",
        "- Submit your work(your reasoning and your code) as a SINGLE .ipynb document. Please rename the document as _HW1_YOURNAME.ipynb_ (for example, _HW1_FELIX.ipynb_). You are responsible for checking that you have correctly submitted the correct document. If your code cannot run, you may receive NO point. \n",
        "\n",
        "- Please justify all short answers with a brief explanation. If you use latex command in the markdown, **2 points** bonus will be awarded.   \n",
        "\n",
        "- You only use the Python packages included in the following cell. You are not allowed to use other advanced package or modules unless you are permitted to. \n",
        "\n",
        "- In your final submission include the plots produced by the unedited code as presented below, as well as any additional plots produced after editing the code during the course of a problem. You may find it necessary to copy/paste relevant code into additional cells to accomplish this.\n",
        "\n",
        "- Feel free to use the lecture notes and other resources. But you\n",
        "must understand, write, and hand in your own answers. In addition, you must write and submit\n",
        "your own code in the programming part of the assignment (we may run your code).\n",
        "If you copy someone else homework solution, both of you may receive ZERO point. \n",
        "\n",
        "\n",
        "- Colab is preferred. However, if you use Anaconda, please download the .mat file locally and save it to the same folder as this homework file. "
      ],
      "metadata": {
        "id": "ipWO4eSUMSIi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Collaboration:** List the names of all people you collaborated with and for which question(s). This is important!"
      ],
      "metadata": {
        "id": "dcGdktD1OzrB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1: Gaussian Mixture Models (30pt)\n",
        "### Q1.1  KL divergence (5pt)\n",
        "In class, we defined the **Kullback-Leibler divergence** (or **KL divergence** for short) between two probability distributions $q$ and $p$, \n",
        "$$ \\text{KL}(q||p)=\\sum_{z=1}^K q(z) \\log\\left( \\frac{q(z)}{p(z)}\\right)$$\n",
        "where $\\sum_{z=1}^K q(z)=1$ and $\\sum_{z=1}^K p(z)=1$. For simplicity, assume $p(z)>0$ for all $z$. \n",
        "\n",
        "Please show the following two key properties\n",
        "- $\\text{KL}(q||p)\\ge 0$ \n",
        "\n",
        "- $\\text{KL}(q||p)=0$ iff $p=q$. "
      ],
      "metadata": {
        "id": "uztB1SSzPZLR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "F5eSGwthPyN6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Q1.2 (optional) Analytical solutions\n",
        "Show the following results, \n",
        "- \\begin{align}\n",
        "\\hat\\pi_k=\\arg\\max_{ \\pi_k} \\sum_{i=1}^N \\phi_{k}^{(i)} \\log \\pi_k = \\frac{1}{N}\\sum_{i=1}^N \\phi_{k}^{(i)}\n",
        "\\end{align}\n",
        "with the constraint that $\\sum_{k}\\pi_k=1$ and $0\\le \\pi_k\\le 1$\n",
        "\n",
        "- \\begin{align}\n",
        "(\\hat{\\mm\\mu}_k, \\hat{\\mm\\Sigma}_k)=\\arg\\max_{ \\mm\\mu_k, \\mm\\Sigma_k} \\sum_{i=1}^N \\phi_{k}^{(i),t} \\log p(\\mathbf{x}^{(i)} |\\mm\\mu_k, \\mm\\Sigma_k) = \\left(\\frac{\\sum_{i=1}^N \\phi_{k}^{(i)}  \\mathbf{x}^{(i)}}{\\sum_{i=1}^N \\phi_{k}^{(i)}}, \\frac{\\sum_{i=1}^N \\phi_{k}^{(i)}  \\left[\\mathbf{x}^{(i)}-\\hat{\\mm\\mu}_k\\right]\\left[\\mathbf{x}^{(i)}-\\hat{\\mm\\mu}_k\\right]^T}{\\sum_{i=1}^N \\phi_{k}^{(i)}}\\right)\n",
        "\\end{align}"
      ],
      "metadata": {
        "id": "5P59Vf6gjvfS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "tW3r1PFvot6n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "### Q1.3. Construct a function to calculate log likelihood (5pt)\n",
        "Say you have applied EM algorithm in the Gaussian Mixture model and have found the optimal parameter $\\hat{\\mm\\theta}=\\{\\hat\\pi_k, \\hat{\\mm\\mu}_k, \\hat{\\mm\\Sigma}_k\\}_{k=1}^K$. Construct a function to calculate the log likelihood $\\ell(\\theta)$"
      ],
      "metadata": {
        "id": "sa_wfQDGP2BH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Q1.3 your code starts here"
      ],
      "metadata": {
        "id": "5bFahnClQrPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Q1.4 Construct a function to calculate Bayesian information criterion (BIC) (5pt)\n",
        "\n",
        "In Gaussian mixture models, one question is how to choose the number of the cluster $K$. This time we cannot simply use elbow method, instead we will use slightly more complicated criterion, Bayesian information criterion (BIC). \n",
        "\n",
        "Remember the definition of BIC is \n",
        "\\begin{align}\n",
        "\\mr{BIC}(K) = \\log p(\\c{D}|\\hat{\\mm\\theta})-\\frac{d_K}{2}\\log(N)\n",
        "\\end{align}\n",
        "The first term is the log-likelihood $\\ell(\\hat{\\mm\\theta})$, $d_K$ is the number of free parameters in the model and $N$ is the number of samples. Overall, the higher BIC value, the better of the model. \n",
        "\n",
        "What is $d_K$ in GMM for $K$ clusters? \n",
        "Please construct a function to calculate the Bayesian information criterion. \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tVOy8UxWUFq8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "K7PSZ6QaYAEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q1.4  your code starts here"
      ],
      "metadata": {
        "id": "wUvL0lu5X9Go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Q1.5. Testing with the synthetic dataset (10pt)\n",
        "Performing Gaussian mixture models over the loop for an increasing number of $K$ from 2 to 6. Note for each $K$, you should run your GMM several times with differnt random initial conditions, to make sure the parameter is not trapped in the local optimum. Plot BIC value vs. the number of the cluster $K$. From the plot, please comment what is the optimal $K$. \n",
        "\n",
        "(It is always a good habit to start your code for some special $K$, say $K=3$. Make sure your code produces the correct result first, then put it into the loop with different $K$. )"
      ],
      "metadata": {
        "id": "QxQd_J9CaXuc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/yexf308/AppliedStatistics/main/Homework/HW4/2DGaussianMixture.csv?raw=true -O 2DGaussianMixture.csv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ehx84loqctkh",
        "outputId": "4fd77ee2-fa34-4283-a776-8f639c47796c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-28 15:36:33--  https://raw.githubusercontent.com/yexf308/AppliedStatistics/main/Homework/HW4/2DGaussianMixture.csv?raw=true\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12901 (13K) [text/plain]\n",
            "Saving to: ‘2DGaussianMixture.csv’\n",
            "\n",
            "\r2DGaussianMixture.c   0%[                    ]       0  --.-KB/s               \r2DGaussianMixture.c 100%[===================>]  12.60K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-07-28 15:36:33 (67.6 MB/s) - ‘2DGaussianMixture.csv’ saved [12901/12901]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.genfromtxt(\"2DGaussianMixture.csv\", delimiter=\",\")\n",
        "X = X[1:]\n",
        "X = X[:,1:]\n",
        "plt.scatter(X[:,0],X[:,1])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "-c1I_wIadFL-",
        "outputId": "c51f5ae0-4e18-46ea-c2ca-b65a7434d0de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q1.5 Your code starts here"
      ],
      "metadata": {
        "id": "P4xlQ_loexvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "tJTPmUCfe1j4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Q1.6 Plot (5pt)\n",
        "After picking the optimal, \n",
        "- Plot the data, with the most likely cluster assignment of each\n",
        "data point indicated by its color. \n",
        "- Mark the mean of each Gaussian \n",
        "- Draw the\n",
        "covariance ellipse for each Gaussian."
      ],
      "metadata": {
        "id": "PbMZFQ-QfAIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q1.6 Your code starts here"
      ],
      "metadata": {
        "id": "Rfq6b8pSfTG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "\n",
        "#Q2: Pandora Recruiting! (20 pt)\n",
        "**Pandora** is a streaming music company and they paid an army of employees to create feature vectors for each song by hand. Suppose you work at Pandora and have feature vectors $\\{\\m{x}^{(i)}\\}_{i=1}^N\\in \\mb{R}^d$ for all $N$ songs in your database, and for a particular user, for some subset $\\c{S}\\subset \\{1, \\dots, N\\}$, has listened to song $i\\in \\c{S}$ exactly $Y^{(i)}\\in \\{1,2,\\dots\\}$ times. You would like to\n",
        "make a playlist for this user so you assume $Y^{(i)}$ is **Poisson distributed** with mean $\\mb{E}[Y^{(i)}|\\m{x}^{(i)}]=\\lambda_i = \\exp(\\m{x}^{(i)}\\m{w})$ for some weight vector $\\m{w}\\in \\mb{R}^d$ reflecting the user's preferences. That is \n",
        "\\begin{align}\n",
        "p(Y^{(i)}=y |\\m{x}^{(i)}, \\m{w})= \\frac{\\lambda_i^y}{y!}\\exp(-\\lambda_i) =\\frac{\\exp(y\\m{x}^{(i)}\\m{w})}{y!}\\exp(-\\exp(\\m{x}^{(i)}\\m{w})) \n",
        "\\end{align}\n",
        "The maximum likelihood estimator is $\\hat{\\m w}= \\arg\\max_{\\m{w}} \\Pi_{i\\in \\c{S}}p(Y^{(i)} |\\m{x}^{(i)}, \\m{w})$. The idea is that you would then construct\n",
        "a playlist out of the items $i\\in \\{1, \\dots, N\\}$ that maximize $\\m{x}^{(i)}\\m{w}$. \n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Q2.1 Solve for $\\hat{\\m{w}}$ (10pt)\n",
        "The estimate $\\hat{\\m{w}}$ has no closed-form solution. Can the optimization problem be transformed into a **convex\n",
        "optimization** problem?  If so, suggest a method of solving for $\\hat{\\m{w}}$ given $\\{(\\m{x}^{(i)}, Y^{(i)})\\}_{i\\in\\c{S}}$. "
      ],
      "metadata": {
        "id": "evq96YN4QvsM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "ORvw6CsBbaYW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Q2.2 Further improvement based on mood (10pt)\n",
        "You solve for the $\\hat{\\m{w}}$ for this user and make a playlist for her. Weeks later you look at her listening history\n",
        "and observe that sometimes she listens to a particular set of songs and skips over others, and at some\n",
        "other point she listens to a different set of songs and skips over others. You have the epiphany that users\n",
        "are human beings whose preferences differ with their mood (e.g., music for workouts, studying, being sad,\n",
        "etc.).  You decide she has $k$ music moods and aim to make $k$ playlists, one for each mood that could be\n",
        "modeled by a different weight vector $\\m{w}$.  The problem is that you don’t know which observation $i\\in \\c{S}$ is\n",
        "assigned to which mood. Describe (in math and words) how you would use the EM algorithm to make $k$ playlists."
      ],
      "metadata": {
        "id": "sizG5FWXbdDo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "ByD6ffnuc3GI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "# Q3: Clustering the BBC News (20pt)\n",
        "The dataset we will consider comes from the BBC (http://mlg.ucd.ie/datasets/bbc.html).\n",
        "The preprocessed dataset consists of the term-document frequency of 99 vocabulary and 1791\n",
        "documents chosen from 5 categories: business, entertainment, politics, sport and tech. \n",
        "\n",
        "After unzipping the folder, there should be four files: bbc.mtx, bbc.terms, bbc.classes,\n",
        "and bbc.centers.\n",
        "- **bbc.mtx**: Original term frequencies stored in a sparse matrix in Matrix Market format: each row is in the form of “termid docid frequency”.\n",
        "\n",
        "- **bbc.terms**: List of content-bearing terms in the corpus, with each line corresponding\n",
        "to a row of the sparse data matrix.\n",
        "\n",
        "- **bbc.classes**: Assignment of documents to natural classes, with each line corresponding to a document.\n",
        "\n",
        "- **bbc.centers**: : Cluster centers for initializing the clusters, with each line corresponding\n",
        "to a center of the cluster.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mm6-1oM_C0BE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/yexf308/AppliedStatistics/main/Homework/HW4/bbc.mtx?raw=true -O bbc.mtx\n",
        "!wget https://raw.githubusercontent.com/yexf308/AppliedStatistics/main/Homework/HW4/bbc.terms?raw=true -O bbc.terms\n",
        "!wget https://raw.githubusercontent.com/yexf308/AppliedStatistics/main/Homework/HW4/bbc.classes?raw=true -O bbc.classes\n",
        "!wget https://raw.githubusercontent.com/yexf308/AppliedStatistics/main/Homework/HW4/bbc.centers?raw=true -O bbc.centers"
      ],
      "metadata": {
        "id": "yDaYwcr8EilK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f_mat = mmread('bbc.mtx').tocsr()\t\t\t# term-document frequency matrix\n",
        "classes = np.loadtxt('bbc.classes',delimiter=\" \")\t\t# The document classes\n",
        "classes=classes.astype(int) # first columns is the index and second column is the true cluster of the clusters.\n",
        "\n",
        "file = open('bbc.terms','r')\n",
        "terms = file.read().splitlines()\t\t\t\t\t# The terms for each row in f_mat\n",
        "file.close()\n",
        "centers = np.loadtxt('bbc.centers',delimiter=\" \")"
      ],
      "metadata": {
        "id": "rX_YQqhGGIJk"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The term frequency vector is not a good metric because of its\n",
        "biases to frequent terms. Your first task is to convert the term frequency into **tfidf**. For more information on tfidf, you may refer to https://github.com/yexf308/AdvancedMachineLearning/blob/main/Fast_KNN_kd_tree.ipynb. \n",
        "\n",
        "The following cell I calculate the tfidf for each doc.  "
      ],
      "metadata": {
        "id": "NQaFBA-DHqlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute tfidf\n",
        "max_f = f_mat.max(axis=0).toarray()\t\t\t\t\t\t\t\t# Max frequency of any word for each doc\n",
        "tfidf = np.array(f_mat / max_f)\t\t\t\t\t\t\t\t\t# Term frequency matrix\n",
        "D = f_mat.shape[1]\t\t\t\t\t\t\t\t\t\t\t\t# Number of documents in corpus\n",
        "idf = np.array(np.log(D / np.sum(f_mat != 0.0, axis=1)))\t\t# Inverse document frequency\n",
        "tfidf = tfidf * idf\t\t\t\t\t\t\t\t\t\t\t\t# tf-idf\n",
        "# tfidf is now your data matrix. You will perform GMM on this dataset. \n"
      ],
      "metadata": {
        "id": "ARym04ckIYhR"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q3.1 GMM with shrinkage (20pt)\n",
        "Run EM with $K = 5$ for 5 iterations. Using “BBC.centers” as the mean and identity as the\n",
        "covariance of the initial clusters. Initialize $\\mm{\\pi}$ uniformly. You need to be careful when updating the covariance matrix $\\mm{\\Sigma}_k$ during M-step. In\n",
        "particular, the MLE can be ill-conditioned because the data is sparse. As usual, to handle this\n",
        "case, we can perform a shrinkage on the MLE: $\\hat{\\mm{\\Sigma}}=(1-\\lambda)\\hat{\\mm{\\Sigma}}_{\\text{MLE}}+\\lambda \\m{I}$, which is equivalent\n",
        "to a MAP estimate of the posterior distribution with some Gaussian prior. For simplicity, in this problem, please\n",
        "use $\\lambda=0.2$. \n",
        "\n",
        "- Compare with the true cluster in `classes`, plot the classification error vs number of iterations.\n",
        "\n",
        "- Plot the log-likelihood vs the number of iterations."
      ],
      "metadata": {
        "id": "E3HoL66LKove"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q3.1  your code starts here"
      ],
      "metadata": {
        "id": "6oHVQ0qhYikZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "91TDXeUSYjim"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "# Q4: SPECTF Heart Data (30pt)\n",
        "In this programming exercise, we will get started with using scikit-learn and python by using an existing\n",
        "decision tree implementation provided with scikit-learn.\n",
        "\n",
        "### Data Set Description\n",
        "We will be applying decision tree learning to the evaluation of cardiac Single Proton Emission Computed\n",
        "Tomography (SPECT) images. We will work with a database of 267 SPECT image sets, each of which corresponds to a patient. Each patient’s scan was classified as either “normal(0)” or “abnormal(1)” by a physician; your job is to train a **classifier** to automatically evaluate SPECT image sets based on this training data. Instead\n",
        "of working with raw image sets, each SPECT image set was processed to extract 44 continuous features\n",
        "that summarize the original SPECT images. Each feature is a number between 0 and 100 corresponding\n",
        "to a “region of interest” in the image during stress or at-rest tests. \n",
        "\n",
        "The data is given in `SPECTF.dat`: the\n",
        "first column represents the class label and the remaining columns represent the features. The SPECTF data\n",
        "originally came from http://archive.ics.uci.edu/ml/datasets/SPECTF+Heart.\n"
      ],
      "metadata": {
        "id": "VN22ZHUSRy8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/yexf308/AppliedStatistics/main/Homework/HW4/SPECTF.dat?raw=true -O SPECTF.dat"
      ],
      "metadata": {
        "id": "hH4XFrJmSw1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.loadtxt('SPECTF.dat', delimiter=',')\n",
        "X = data[:, 1:]\n",
        "y = np.array([data[:, 0]]).T\n",
        "n,d = X.shape"
      ],
      "metadata": {
        "id": "tEPK78vZUHE2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YBQmLTFUcXl",
        "outputId": "269b9da1-cf7b-4c0f-ccdf-ce640229ad7c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(267, 44)\n",
            "(267, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Q4.1 Cross-validation (20pt)\n",
        "In this problem, we will cross-validate to determine the hyperparameter: the  maximum layer of the decision tree. \n",
        "1. Randomize the order of the instances in the data set, and split the data into training, validation and testing sets with 80%, 10% and 10%. \n",
        "\n",
        "2. Perform 8-fold cross-validation over the training and validation datasets, and record **the training error and validation error** for the decision tree with maximum layer from 1 to 10. \n",
        "\n",
        "3. Since the contruction of decision tree in sklearn is random, please repeat the process of step 1 and 2 **100 trials**, and report **the mean and standard deviation** of the training error and validation error over all 100 trials of 8-fold cross-validation. Be certain to shuffle the data at the start of each trial, but never within a trial.\n",
        "\n",
        "4. Plot mean of both errors in the same figure vs the maximum layer and report the optimal maximum layer. \n",
        "\n",
        "5. Combine the training and validation dataset, build the decision tree classifier with the optimal maximum layer and report the testing error on predicting the testing dataset.  \n",
        "\n",
        "Note although scikit-learn provides libraries that implement cross-fold validation, you may not use them\n",
        "for this assignment – you must implement cross-fold validation yourself.\n",
        "\n",
        "To display the standard deviations on the plot, see errorbar (http://matplotlib.org/examples/statistics/errorbar_demo_features.html) functions in matplotlib."
      ],
      "metadata": {
        "id": "AR5w6tLi7Oln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q4.1  your code starts here"
      ],
      "metadata": {
        "id": "E5iZ9hbNsy_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "v6rWgnNAtA_b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Q4.2 Generating a Learning Curve (10pt)\n",
        "In this question, we will use the optimal maximum layer as we got from the last question. We combine the training and validation dataset into the total training set. \n",
        "\n",
        "We will generate and output a plot showing the learning curve over the total training data. The learning curve should **plot the mean and standard deviation of the testing error** for $10\\%, 20\\%, \\dots, 100\\% $ of the total training data. Note that $100\\%$ of the total training data corresponds to $90\\%$ of the complete data set. As before, the learning curve statistics should be computed over 100 trials for each different amount of training data. "
      ],
      "metadata": {
        "id": "wgybY1itwWqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q4.1  your code starts here"
      ],
      "metadata": {
        "id": "1PfM9rv84C2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "WaFvO4X-4DUw"
      }
    }
  ]
}