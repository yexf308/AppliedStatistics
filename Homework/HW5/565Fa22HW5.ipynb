{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "565Fa22HW5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7i7lfYXmoBVBYJZG2/Nv8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yexf308/AppliedStatistics/blob/main/Homework/HW5/565Fa22HW5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hPY0Yzeq6dnP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa2afeb7-17cf-4f67-b8fa-febc8d4e2e4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        }
      ],
      "source": [
        "%pylab inline \n",
        "import pandas as pd\n",
        "from scipy import linalg\n",
        "from sklearn import tree\n",
        "from itertools import combinations\n",
        "import scipy\n",
        "import scipy.io as io\n",
        "from scipy.io import mmread\n",
        "import scipy.sparse as sparse"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\def\\m#1{\\mathbf{#1}}$\n",
        "$\\def\\mm#1{\\boldsymbol{#1}}$\n",
        "$\\def\\mb#1{\\mathbb{#1}}$\n",
        "$\\def\\c#1{\\mathcal{#1}}$\n",
        "$\\def\\mr#1{\\mathrm{#1}}$\n",
        "$\\newenvironment{rmat}{\\left[\\begin{array}{rrrrrrrrrrrrr}}{\\end{array}\\right]}$\n",
        "$\\newcommand\\brm{\\begin{rmat}}$\n",
        "$\\newcommand\\erm{\\end{rmat}}$\n",
        "$\\newenvironment{cmat}{\\left[\\begin{array}{ccccccccc}}{\\end{array}\\right]}$\n",
        "$\\newcommand\\bcm{\\begin{cmat}}$\n",
        "$\\newcommand\\ecm{\\end{cmat}}$\n",
        "# Homework 5\n",
        "## Homework guideline\n",
        "- The deadline is **Dec 7th 10:30am**. Submission after the deadline will not be graded. \n",
        "\n",
        "\n",
        "- Submit your work(your reasoning and your code) as a SINGLE .ipynb document. Please rename the document as _HW1_YOURNAME.ipynb_ (for example, _HW1_FELIX.ipynb_). You are responsible for checking that you have correctly submitted the correct document. If your code cannot run, you may receive NO point. \n",
        "\n",
        "- Please justify all short answers with a brief explanation. \n",
        "\n",
        "\n",
        "\n",
        "- You only use the Python packages included in the following cell. You are not allowed to use other advanced package or modules unless you are permitted to. \n",
        "\n",
        "- In your final submission include the plots produced by the unedited code as presented below, as well as any additional plots produced after editing the code during the course of a problem. You may find it necessary to copy/paste relevant code into additional cells to accomplish this.\n",
        "\n",
        "- Feel free to use the lecture notes and other resources. But you\n",
        "must understand, write, and hand in your own answers. In addition, you must write and submit\n",
        "your own code in the programming part of the assignment (we may run your code).\n",
        "If you copy someone else homework solution, both of you may receive ZERO point. \n",
        "\n",
        "\n",
        "- Colab is preferred. However, if you use Anaconda, please download the .mat file locally and save it to the same folder as this homework file. \n",
        "\n"
      ],
      "metadata": {
        "id": "QV2D7Og46iW5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Collaboration:** List the names of all people you collaborated with and for which question(s). This is important!"
      ],
      "metadata": {
        "id": "qwOQPe_F7eC9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Important information\n",
        "One of the most difficult aspects of machine learning is that your classifier must generalize well to unseen\n",
        "data. In the following questions, we are supplying you with labeled training data and unlabeled test data. Specifically,\n",
        "**you will not have access to the labels for the test data**, which we will use to grade your homework. You will fit the best model that you can to the given data and then use that model to predict labels for the test data. It is these predicted labels that you will submit, and we will grade your submission based on your test\n",
        "accuracy (relative to the best performance you should be able to obtain). We will **compute your test accuracy based on your predicted labels for the test data and the true test labels**. Note also that we will not be providing any feedback on your predictions\n",
        "or your test accuracy when you submit your assignment, so you must do your best without feedback on your\n",
        "test performance."
      ],
      "metadata": {
        "id": "bFdid6YzIkWV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Q1: Boosted Decision Tree (40pt)\n",
        "In class, we mentioned that boosted decision trees have been shown to be one of the best “out-of-the-box”\n",
        "classifiers. (That is, if you know nothing about the data set and can’t do parameter tuning, they will likely\n",
        "work quite well.) Boosting allows the decision trees to represent a much more complex decision surface than\n",
        "a single decision tree.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Q1.1 Implementation (15pt)\n",
        "Write a class that implements a boosted decision tree classifier. Your implementation may rely on the\n",
        "decision tree classifier already provided in `sklearn.tree.DecisionTreeClassifier`. But you\n",
        "**must implement the boosting process yourself**. (The scikit_learn module actually provides boosting as a\n",
        "meta-classifier, but you must not use it in your implementation.) Each decision tree in the ensemble should\n",
        "be limited to a maximum depth as specified in the `BoostedDT` constructor. You can configure the maximum\n",
        "depth of the tree via the `max_depth` argument to the `DecisionTreeClassifier` constructor.\n",
        "\n",
        "You must implement the following class: \n",
        "\n",
        "- `__init__(numBoostingIters = 100, maxTreeDepth = 3)`:  the constructor, which takes in the number of boosting iterations (default value: 100) and the maximum depth of the member decision trees (default: 3). \n",
        "\n",
        "- `fit(X,y)`: train the classifier from labeled data $(\\m{X}, \\m{y})$\n",
        "\n",
        "- `predict(X)`:  return an array of $N$ predictions for each of $N$ rows of $\\m{X}$. \n",
        "\n",
        "Be very careful not\n",
        "to change the class. You should configure your boosted decision tree classifier to be the best “out-of-the-box”\n",
        "classifier you can; you may not modify the constructor to take in additional parameters (e.g., to configure\n",
        "the individual decision trees).\n",
        "\n",
        "There is one additional change you need to make to **AdaBoost** beyond the algorithm described in class.\n",
        "AdaBoost by default only works with binary classes, but in this case, we have a multi-class classification\n",
        "problem. One variant of AdaBoost, called **AdaBoost-SAMME**, easily adapts AdaBoost to multiple classes.\n",
        "Instead of using the equation $\\beta_t = \\frac{1}{2}\\ln\\left(\\frac{1-\\epsilon}{\\epsilon}\\right)$ in AdaBoost, , you should use the AdaBoost-SAMME equation \n",
        "\\begin{align}\n",
        "\\beta_t = \\frac{1}{2}\\left(\\ln\\left(\\frac{1-\\epsilon}{\\epsilon}\\right)+\\ln(K-1)\\right)\n",
        "\\end{align}\n",
        "where $K$ is the total number of classes. This will force $\\beta_t\\ge 0$  as long as the classifier is no worse than\n",
        "random guessing. Note that when $K=2$, AdaBoost-SAMME reduces to AdaBoost. \n",
        "\n",
        "You should test your `BoostedDT` model to a\n",
        "regular decision tree on the iris data with a 50:50 training/testing split. You should see that your `BoostedDT`\n",
        "model is able to obtain 97% accuracy vs the 96% accuracy of regular decision trees. Make certain that your\n",
        "implementation works correctly before moving on to the next part."
      ],
      "metadata": {
        "id": "IzBhO8uB89Xv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q1.1 \n",
        "class BoostedDT:\n",
        "\n",
        "    def __init__(self, num_boosting_iters=100, max_tree_depth=3):\n",
        "        \"\"\"\n",
        "        Constructor\n",
        "        \"\"\"\n",
        "        # TODO\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Trains the model\n",
        "        Arguments:\n",
        "            X is a n-by-d numpy array\n",
        "            y is an n-dimensional numpy array\n",
        "        \"\"\"\n",
        "        # TODO: np.unique and np logical functions (logical_and/or/not) may be helpful to your implementation\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Used the model to predict values for each instance in X\n",
        "        Arguments:\n",
        "            X is a n-by-d numpy array\n",
        "        Returns:\n",
        "            an n-dimensional numpy array of the predictions\n",
        "        \"\"\"\n",
        "        # TODO\n"
      ],
      "metadata": {
        "id": "LYvQiivRA5vP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test your code \n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris \n",
        "\n",
        "# load the data set\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "n, d = X.shape\n",
        "nTrain = int(0.5*n)  # training on 50% of the data\n",
        "\n",
        "# shuffle the data\n",
        "idx = np.arange(n)\n",
        "np.random.seed(13)\n",
        "np.random.shuffle(idx)\n",
        "X = X[idx]\n",
        "y = y[idx]\n",
        "\n",
        "# split the data\n",
        "Xtrain = X[:nTrain, :]\n",
        "ytrain = y[:nTrain]\n",
        "Xtest = X[nTrain:, :]\n",
        "ytest = y[nTrain:]\n",
        "\n",
        "# train the decision tree\n",
        "modelDT = DecisionTreeClassifier()\n",
        "modelDT.fit(Xtrain, ytrain)\n",
        "\n",
        "# train the boosted DT\n",
        "modelBoostedDT = BoostedDT(num_boosting_iters=100, max_tree_depth=2)\n",
        "modelBoostedDT.fit(Xtrain, ytrain)\n",
        "\n",
        "# output predictions on the remaining data\n",
        "ypred_DT = modelDT.predict(Xtest)\n",
        "ypred_BoostedDT = modelBoostedDT.predict(Xtest)\n",
        "\n",
        "# compute the training accuracy of the model\n",
        "accuracyDT = accuracy_score(ytest, ypred_DT)\n",
        "accuracyBoostedDT = accuracy_score(ytest, ypred_BoostedDT)\n",
        "\n",
        "print(\"Decision Tree Accuracy = \" + str(accuracyDT))\n",
        "print(\"Boosted Decision Tree Accuracy = \" + str(accuracyBoostedDT))"
      ],
      "metadata": {
        "id": "PzEidNxZCBBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "### Q1.2: Generalizing to Unseen Data (10pt)\n",
        "\n",
        "Once your boosted decision tree is working, train your `BoostedDT` on the labeled data available in the file: `challengeTrainLabele.txt`.  The class labels are specified in the last column of data.  Then, use the trained `BoostedDT` classifier to predict a label $y\\in\\{1,\\dots, 9\\}$  for each unlabeled instance in `challengeTestUnlabeled.txt`. \n",
        "\n",
        "- Record the expected accuracy of your model. \n",
        "- Your implementation should output a comma-separated list of predicted labels, such as,\n",
        "1, 2, 1, 9, 4, 1, 3, 1, 5, 3, 4, 2, 8, 3, 1, 6, 3 ...\n",
        " \n",
        "- Save the comma-separated list into\n",
        "a text file named `predictions-BoostedDT.txt`. You may use the following command: `np.savetxt('predictions-BoostedDT.txt', predictions, delimiter=',')`. Your file will be saved in the folder of colab and you can download that from the file tab. \n",
        "\n",
        "\n",
        "\n",
        "Be very careful not to shuffle the instances in `challengeTestUnlabeled.txt`.  The first predicted label\n",
        "should correspond to the first unlabeled instance in the testing data. The number of predictions should\n",
        "match the number of unlabeled test instance.\n"
      ],
      "metadata": {
        "id": "E_RgYGcPkDi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/yexf308/AppliedStatistics/main/Homework/HW5/challengeTrainLabeled.txt?raw=true -O challengeTrainLabeled.txt\n",
        "!wget https://raw.githubusercontent.com/yexf308/AppliedStatistics/main/Homework/HW5/challengeTestUnlabeled.txt?raw=true -O challengeTestUnlabeled.txt"
      ],
      "metadata": {
        "id": "R3M9d-75jhDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = np.loadtxt('challengeTrainLabeled.txt', delimiter=',')\n",
        "test  = np.loadtxt('challengeTestUnlabeled.txt', delimiter=',')"
      ],
      "metadata": {
        "id": "4RzKV-akjyNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q1.2 Your code starts here. "
      ],
      "metadata": {
        "id": "laPehOMVqdh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Q1.3 Training the Best Classifier (15pt)\n",
        "Now, train the very best classifier for the challenge data, and use that classifier to output a second vector\n",
        "of predictions for the test instances. You may use any machine learning algorithm you like, and may tune\n",
        "it any way you wish. You may use the method and helper functions built into scikit_learn.  you do not need\n",
        "to implement the method yourself, but may if you wish. If you can think of a way that the unlabeled data in `challengeTestUnlabeled.txt` would be useful during the training process, you are welcome to let\n",
        "your classifier have access to it during training.\n",
        "\n",
        "Again, be careful not to shuffle the test instances; the\n",
        "order of the predictions must match the order of the test instances. \n",
        "\n",
        "- Record the expected accuracy of your model.\n",
        "\n",
        "- save the comma-separated list into a\n",
        "text file named `predictions-BestClassifier.txt`. this file should have one line of text that contains the\n",
        "list of predictions.\n",
        "\n",
        "- Write a brief paragraph (6–8 sentences max) describing the best machine learning classifier you found, its\n",
        "optimal parameter settings (if any), and how you trained the model."
      ],
      "metadata": {
        "id": "UzMBneFnrGaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q1.3 Your code starts here. "
      ],
      "metadata": {
        "id": "zbRMulsgBuYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "JAN2xmi0Bw0N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Q2: California House Price Prediction (60pt)\n",
        "In data science job interview, you will be given a large dataset and you need to make the predicition on the test dataset as online assessment usually within 3 hours. It assesses a candidate’s ability to analyze data, extract information, building model and machine learning skills, as well as their ability to take advantage of Python and its data science libraries. In this assignment, you will be given such real world datasets with the training data and testing data. Real world datasets, unlike synthetic data, is very messy, you need to preprocess these data first. You may also refer to this quick pandas tutorial: https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html. \n",
        "\n",
        "Like the previous question, you may use any machine learning algorithm you like, and may tune\n",
        "it any way you wish. You may use the method and helper functions built into scikit_learn.  you do not need\n",
        "to implement the method yourself, but may if you wish. If you can think of a way that the unlabeled data would be useful during the training process, you are welcome to let\n",
        "your classifier have access to it during training.\n",
        "\n",
        "**Your Goal:**\n",
        "- You need to save the comma-separated list into a\n",
        "text file named `predictions_housing.txt`. this file should have one line of text that contains the\n",
        "list of predictions of housing price.  \n",
        "\n",
        "- Write a paragraph to describe the best machine learning classifier you found, its\n",
        "optimal parameter settings (if any), and how you trained the model.\n",
        "\n",
        "**Data access:** \n",
        "\n",
        "The training data is stored in https://drive.google.com/file/d/1WfFkiKLBzTRh8zGDNYQXGUnq8-DK757m/view?usp=sharing. \n",
        "\n",
        "The testing data is stored in https://drive.google.com/file/d/1Met2KysUV0shr6t2JiS7RWXMAKiueiG2/view?usp=sharing. \n",
        "\n",
        "\n",
        "Once you open the link in the brower, make sure you click the \"Add shortcut to Drive\" and now your google drive should show up the two csv files.  Then you run the following code to link colab to your google drive.\n",
        "\n",
        "**Data description:**\n",
        "The task is to predict house sale prices based on the house information, such as # of bedrooms, living areas, locations, near-by schools, and the seller summary. It covers almost every aspects of residential homes. The data consist of houses sold in California on 2020, with 30000 training labeled dataset and 15000 unlabeled dataset. \n",
        "\n",
        "\n",
        "**Metric/Score:** Root-Mean-Squared-Error (RMSE) between the logarithm of the predicted value and the logarithm of the observed sales price. (Taking logs means that errors in predicting expensive houses and cheap houses will affect the result equally.)\n",
        "\n",
        "---\n",
        "\n",
        "**Bonus Points will be given to top 3 scores!**\n",
        "\n"
      ],
      "metadata": {
        "id": "m_J6vHYcDkz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os \n",
        "os.chdir(\"/content/drive/My Drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjX3K6zKz3rx",
        "outputId": "9eca30e7-b924-47b3-cfd1-612850bf2d7c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv('house_train.csv')\n",
        "df_test  = pd.read_csv('house_test.csv')\n"
      ],
      "metadata": {
        "id": "Np-G4OSk0y0p"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train"
      ],
      "metadata": {
        "id": "jNtUhEp21EYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test"
      ],
      "metadata": {
        "id": "2ZuUTXLl1emq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code starts here"
      ],
      "metadata": {
        "id": "JR_A_FmFDC1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "mIDiBJFGDEt_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Q3: (optional) Correction to your previous homework question\n",
        "You may pick any one question in homework 1-4 that didn't perform well, and now you have the chance to correct your mistakes. If you successfully correct your mistakes, your previous grade will be replaced by the current score, e.g., say you want to correct HW3Q3: yelp recruiting, your previous score is 10/30 and after successful attempt, your score becomes 25/30. You will be awarded 15 bonus point here. \n",
        "\n",
        "**State Your question that you want to correct:**"
      ],
      "metadata": {
        "id": "kLyFlOHlDHaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your new code starts here"
      ],
      "metadata": {
        "id": "X0YWIlYqG9sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your New Solution:"
      ],
      "metadata": {
        "id": "GTWPJIQDG_sB"
      }
    }
  ]
}